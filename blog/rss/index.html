<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Manuel Viera]]></title><description><![CDATA[I'm Manu and this is my personal lifelog. Here you'll find some tech posts, self-tracking metrics and other random thoughts.]]></description><link>http://manuelviera.com/</link><image><url>http://manuelviera.com/favicon.png</url><title>Manuel Viera</title><link>http://manuelviera.com/</link></image><generator>Ghost 3.19</generator><lastBuildDate>Sun, 20 Sep 2020 15:55:49 GMT</lastBuildDate><atom:link href="http://manuelviera.com/blog/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[PostgreSQL and read-only users - the easiest way]]></title><description><![CDATA[Sometimes someone asks you to create a read-only user just for backups, giving a non-privileged user to a non-technical person. In this post, I'll show you the easiest way to create one.]]></description><link>http://manuelviera.com/blog/postgresql-and-read-only-users-the-easiest-way/</link><guid isPermaLink="false">5f5fdb57db2a88526e3dffce</guid><category><![CDATA[tech]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Sun, 20 Sep 2020 15:54:17 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1519658422992-0c8495f08389?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1519658422992-0c8495f08389?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ" alt="PostgreSQL and read-only users - the easiest way"><p>Here you have the quick recipe:</p>
<pre><code>CREATE ROLE readonly;
GRANT CONNECT ON DATABASE mydatabase TO readonly;
\connect mydatabase
GRANT USAGE ON SCHEMA public to readonly;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly;
CREATE USER myuser1 WITH PASSWORD 'secret_passwd';
GRANT readonly TO myuser1;
</code></pre>
<h2 id="thedeepdive">The deep dive(?)</h2>
<p>Let's suppose you already have a well-securitized database with one or more users with the right privileges. If you still don't have your PostgreSQL database well protected, I recently wrote about <a href="https://manuelviera.com/blog/postgresql-and-how-to-shield-your-databases-well/">how to securitize your database access well</a>. You might find it useful.</p>
<p>Okay, so imagine someone asking you to create a read-only user to let an external provider connect and consume data, exporting reports, or whatever.</p>
<p>As we won't want to repeat all this process each time we need to create a read-only user, we'll create a role and then assign it.</p>
<p>So, for creating the read-only role, just type the following:</p>
<pre><code>CREATE ROLE readonly;
</code></pre>
<p>We want this role to be able to connect to our database, so:</p>
<pre><code>GRANT CONNECT ON DATABASE mydatabase TO readonly;
</code></pre>
<p>But, as you might know, this permission is not enough; we need to allow it to allow access to objects in the <code>public</code> schema.</p>
<pre><code>\connect mydatabase
GRANT USAGE ON SCHEMA public to readonly;
</code></pre>
<p>As we may want to allow it to access all tables in the database, we'll type:</p>
<pre><code>GRANT SELECT ON ALL TABLES IN SCHEMA public TO readonly;
</code></pre>
<p>But, If you only want to give access to specific tables, then type:</p>
<pre><code>GRANT SELECT ON table_name TO readonly;
</code></pre>
<p>Now we have the role ready to use, so we're going to create a user and add it as a member.</p>
<pre><code>CREATE USER myuser1 WITH PASSWORD 'secret_passwd';
GRANT readonly TO myuser1;
</code></pre>
<p>And that's it! Next time you need to create a read-only user it'll be a quick done task ;-)</p>
<hr>
<p>If you have any question, doubt, or any improvement, feel free to let me know in this <a http: manuelviera.com blog postgresql-and-read-only-users-the-easiest-way href>Twitter thread</a> :)</p>
<p>If you found it useful, coffee is always appreciated. Thanks in advance!</p>
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="mviera" data-color="#eaa700" data-emoji data-font="Arial" data-text="Buy me a coffee" data-outline-color="#000" data-font-color="#000" data-coffee-color="#fff"></script>
<h3 id="moreinfoat">More info at</h3>
<p><a href="https://aws.amazon.com/de/blogs/database/managing-postgresql-users-and-roles/">Managing PostgreSQL users and roles</a></p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[PostgreSQL and how to shield your databases well]]></title><description><![CDATA[Security matters, especially in databases. Let me show you how to secure your database in the right way.]]></description><link>http://manuelviera.com/blog/postgresql-and-how-to-shield-your-databases-well/</link><guid isPermaLink="false">5f5e101619f8b01255400608</guid><category><![CDATA[tech]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Sun, 13 Sep 2020 17:09:07 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1515974256630-babc85765b1d?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1515974256630-babc85765b1d?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ" alt="PostgreSQL and how to shield your databases well"><p>The recipe:</p>
<pre><code>CREATE USER myuser with password 'secret_passwd' role postgres;
CREATE DATABASE mydatabase with owner myuser;
\connect mydatabase
REMOVE ALL ON DATABASE mydatabase FROM public;
REVOKE ALL ON SCHEMA public FROM public;    
ALTER SCHEMA public owner to myuser;
REVOKE myuser FROM postgres;
</code></pre>
<hr>
<h2 id="thedeepdive">The deep dive</h2>
<h3 id="firstthingsfirst">First things first</h3>
<p>There are a few things you need to know to understand a bit about how PostgreSQL works.</p>
<ol>
<li>
<p><code>CREATE USER</code> and <code>CREATE GROUP</code> are aliases for the <code>CREATE ROLE</code> statement. A user is just a role with <code>LOGIN</code> privileges.</p>
<pre><code> CREATE USER = CREATE ROLE + LOGIN privilege
</code></pre>
</li>
<li>
<p>PostgreSQL has a <code>public</code> backend role, and every new user and role inherits permissions from it.</p>
</li>
<li>
<p>When a new database is created, PostgreSQL creates a schema called <code>public</code> and grants access on this schema to the <code>public</code> backend role. Mmm... too many things called <em>public</em> here, don't you think?</p>
</li>
<li>
<p>Because of this default behavior, any user can connect to new databases and create objects in each database's <code>public</code> schema.</p>
</li>
</ol>
<h3 id="createtheuser">Create the user</h3>
<pre><code>CREATE USER myuser with password 'secret_passwd' role postgres;
</code></pre>
<p>This statement will create a new user, and it'll add <code>postgres</code> role/user into <code>myuser</code> role. I know, syntax may look confusing.</p>
<h3 id="createthedatabase">Create the database</h3>
<pre><code>CREATE DATABASE mydatabase with owner myuser;
</code></pre>
<p>It creates a new database named <code>mydatabase</code> and makes <code>myuser</code> role the owner.</p>
<h3 id="securizesthedatabase">Securizes the database</h3>
<pre><code>\connect mydatabase
REMOVE ALL ON DATABASE mydatabase FROM public;
REVOKE ALL ON SCHEMA public FROM public;
</code></pre>
<p>Revokes all privileges on the new database and on the <code>public</code> schema to the <code>public</code> role. I mean, this revokes public access to the database.</p>
<h3 id="delegatesownershipofpublicschema">Delegates ownership of <code>public</code> schema</h3>
<pre><code>ALTER SCHEMA public owner to myuser;
</code></pre>
<p>Now the user is the real owner.</p>
<h3 id="thefinalpart">The final part</h3>
<p>Execute this query if you want to revoke access to this database even to <code>postgres</code> user. It's up to you.</p>
<pre><code>REVOKE myuser FROM postgres;
</code></pre>
<p>Remember. After this, even though <code>postgres</code> user, which is the user with more RDS privileges, won't have access to that database. It'll only be accessible for <code>myuser</code> user.</p>
<p>In case you have to operate on it with <code>postgres</code> user, you'll need to grant access for it.</p>
<pre><code>GRANT myuser TO postgres;
</code></pre>
<p>If not, you'll get a <code>permission denied</code> error.</p>
<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><p>If you have any question, doubt, or any improvement I could do, feel free to let me know in this <a href="https://twitter.com/mviera/status/1305246434023870465">Twitter thread</a> :)</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html-->If you found it useful, coffee is always appreciated. Thanks in advance!
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="mviera" data-color="#eaa700" data-emoji data-font="Arial" data-text="Buy me a coffee" data-outline-color="#000" data-font-color="#000" data-coffee-color="#fff"></script><!--kg-card-end: html--><!--kg-card-begin: markdown--><h3 id="moreinfoat">More info at</h3>
<p><a href="https://aws.amazon.com/de/blogs/database/managing-postgresql-users-and-roles/">Managing PostgreSQL users and roles</a><br>
<a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.PostgreSQL.CommonDBATasks.html#Appendix.PostgreSQL.CommonDBATasks.Access">Managing PostgreSQL Database Access</a><br>
<a href="https://www.postgresql.org/docs/9.0/sql-grant.html">PostgreSQL GRANT Documentation</a><br>
<a href="https://www.postgresql.org/docs/9.1/sql-revoke.html">PostgreSQL REVOKE Documentation</a></p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Media consumption in August 2020]]></title><description><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Read 3 books <output>(14h 36 min)</output> and 6 articles.</li>
<li>Watched 3 movies <output>(9h 35 min)</output>, 1 TV episodes <output>(51 min)</output> and 1 talk <output>(19 min)</output>.</li>
<li>Listened to 0 podcasts episodes <output>(0 min)</output>.</li>
<li>Played 3 video games <output>(30h 41 min)</output>.</li>
</ul>
<h4 id="books">Books</h4>
<p><a href="https://www.amazon.es/Infrastructure-Code-Comprehensive-Managing-English-ebook/dp/B07WZ5SV99">Infrastructure as Code</a> <output>(Austin Young)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 100%</output></p>
<p><a href="https://www.amazon.es/libro-cerebro-quiere-Crecimiento-personal/dp/8416720622/">El libro que</a></p>]]></description><link>http://manuelviera.com/blog/media-consumption-in-august-2020/</link><guid isPermaLink="false">5f29d2384501b8255139fd84</guid><category><![CDATA[self-tracking]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Mon, 31 Aug 2020 21:40:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Read 3 books <output>(14h 36 min)</output> and 6 articles.</li>
<li>Watched 3 movies <output>(9h 35 min)</output>, 1 TV episodes <output>(51 min)</output> and 1 talk <output>(19 min)</output>.</li>
<li>Listened to 0 podcasts episodes <output>(0 min)</output>.</li>
<li>Played 3 video games <output>(30h 41 min)</output>.</li>
</ul>
<h4 id="books">Books</h4>
<p><a href="https://www.amazon.es/Infrastructure-Code-Comprehensive-Managing-English-ebook/dp/B07WZ5SV99">Infrastructure as Code</a> <output>(Austin Young)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 100%</output></p>
<p><a href="https://www.amazon.es/libro-cerebro-quiere-Crecimiento-personal/dp/8416720622/">El libro que tu cerebro no quiere leer</a> <output>(David del Rosario)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 100%</output></p>
<p><a href="https://www.amazon.es/gp/product/B01LXWQUFF/">Docker Deep Dive</a> <output>(Nigel Poulton)</output><br>
▓▓▓░░░░░░░░░░░░ <output>Progress: 21%</output></p>
<h4 id="articles">Articles</h4>
<p><a href="https://www.sovereignman.com/trends/4-countries-welcoming-the-digital-nomads-during-covid-28499/">4 countries welcoming the digital nomads during Covid</a> <output>(Simon Black)</output></p>
<p><a href="https://www.deprocrastination.co/blog/how-to-overcome-procrastination-by-understanding-the-fogg-behavior-model">How to stop procrastinating by using the Fogg Behavior Model</a> <output>(deprocrastination.co)</output></p>
<p><a href="https://www.deprocrastination.co/blog/should-i-quit-video-games">Should I quit video games?</a> <output>(deprocrastination.co)</output></p>
<p><a href="https://www.deprocrastination.co/blog/4-simple-ways-to-make-your-to-do-list-less-overwhelming">4 ways to make your to-do lists less overwhelming</a> <output>(deprocrastination.co)</output></p>
<p><a href="https://www.defensecode.com/public/DefenseCode_Unix_WildCards_Gone_Wild.txt">Back To The Future: Unix Wildcards Gone Wild</a> <output>(Leon Juranic)</output></p>
<h4 id="talk">Talk</h4>
<p><a href="https://www.youtube.com/watch?v=Rai3pwH3XrU">Guillaume Néry: The exhilarating peace of freediving</a> <output>(TED)</output></p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Find and the importance of parameters order]]></title><description><![CDATA[Parameter order matters. Especially in commands such as find. This post covers a common problem using find when deleting files and some tips to avoid it.]]></description><link>http://manuelviera.com/blog/find-and-the-importance-of-parameters-order/</link><guid isPermaLink="false">5f54f68bd6502f239e9073e6</guid><category><![CDATA[tech]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Mon, 10 Aug 2020 14:53:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1586769852836-bc069f19e1b6?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1586769852836-bc069f19e1b6?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Find and the importance of parameters order"><p>Someone texted me with this tweet a few weeks ago. It made me remember how important the order of the parameters in some commands could be. Let's see the tweet.</p>
<!--kg-card-end: markdown--><figure class="kg-card kg-embed-card"><blockquote class="twitter-tweet" data-width="550"><p lang="en" dir="ltr">I wanted to delete every file called &quot;contents.html&quot; so I ran:<br><br>find -type f -delete -name contents.html<br><br>It worked! But it also deleted every other file.<br><br>find&#39;s args are ordered. &quot;delete&quot; works on every match before it, ignoring anything after. &quot;name&quot; should have gone first.</p>&mdash; Tomas Sedovic (@TomasSedovic) <a href="https://twitter.com/TomasSedovic/status/1226462687170875398?ref_src=twsrc%5Etfw">February 9, 2020</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</figure><!--kg-card-begin: markdown--><p>As you may have noticed, some commands, such as find, take its parameters in order. So, this command:</p>
<pre><code>find -type f -delete -name contents.html
</code></pre>
<p>is completely different from this another one:</p>
<pre><code>find -type f -name contents.html -delete
</code></pre>
<p><mark>The first one says find to look for every regular file and delete it. The second one says to look for every standard file that matches precisely with <code>contents.html</code> and then delete it.</mark></p>
<p>As Tomas says in his tweet, the first one worked, but unfortunately, deleted all files, which could be a mess in a production system.</p>
<h2 id="sohowtoavoidthiskindofsituation">So, how to avoid this kind of situation?</h2>
<p>First of all, mainly when I'm in a production system, I prefer to start typing a «<code>#</code>» as the first character. Why? Because I want to <mark>avoid executing an unfinished command by hitting the <code>Enter</code> key by mistake</mark>.</p>
<p>Instead of this, I <mark>always print the find's output first to ensure that it finds what we need</mark>.</p>
<pre><code>find -type f -name contents.html -exec echo {} \;
</code></pre>
<p>This command will print the whole list of files which name matches precisely with «contents.html». Once we've ensured the output is ok, then we can delete them.</p>
<pre><code>find -type f -name contents.html -exec rm -f {} \;
</code></pre>
<p>Another alternative to this command could be passing the output through a pipe, and then use xargs and rm.</p>
<pre><code>find -type f -name contents.html | xargs rm -f
</code></pre>
<p>Now you don't have excuses! Don't forget, parameter order matters. When in production systems, I always try not to be creative.</p>
<p>So memorize the commands you usually use and write their parameters always the same order. Always. <mark>Being creative in production is not a good idea</mark>. Don't deal with the devil ;-)</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Media consumption in July 2020]]></title><description><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Read 1 books <output>(458 min)</output> and 13 articles.</li>
<li>Watched 1 movies <output>(120 min)</output>, 18 TV episodes <output>(819 min)</output> and 2 talks <output>(123 min)</output>.</li>
<li>Listened to 0 podcasts episodes <output>(0 min)</output>.</li>
<li>Played 2 video games <output>(2135 min)</output>.</li>
</ul>
<h4 id="books">Books</h4>
<p><a href="https://www.amazon.es/When-Scientific-Secrets-Perfect-Timing/dp/0525542787/">When. The Scientific Secrets Of Perfect Timing</a> <output>(Daniel H Pink)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 0-100%</output></p>
<h4 id="games">Games</h4>]]></description><link>http://manuelviera.com/blog/media-consumption-in-july-2020/</link><guid isPermaLink="false">5f29cb4a4501b8255139fd35</guid><category><![CDATA[self-tracking]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Tue, 04 Aug 2020 21:09:58 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Read 1 books <output>(458 min)</output> and 13 articles.</li>
<li>Watched 1 movies <output>(120 min)</output>, 18 TV episodes <output>(819 min)</output> and 2 talks <output>(123 min)</output>.</li>
<li>Listened to 0 podcasts episodes <output>(0 min)</output>.</li>
<li>Played 2 video games <output>(2135 min)</output>.</li>
</ul>
<h4 id="books">Books</h4>
<p><a href="https://www.amazon.es/When-Scientific-Secrets-Perfect-Timing/dp/0525542787/">When. The Scientific Secrets Of Perfect Timing</a> <output>(Daniel H Pink)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 0-100%</output></p>
<h4 id="games">Games</h4>
<p><a href="https://www.amazon.es/Ghost-Tsushima-Edici%C3%B3n-Est%C3%A1ndar-Exclusiva/dp/B085LYTVG1/">Ghost of Tsushima</a> <output>(Sucker Punch)</output></p>
<p><a href="https://www.amazon.es/505-Games-Control/dp/B07K3GRFMS/">Control</a> <output>(505 Games)</output></p>
<h4 id="recommendedarticles">Recommended articles</h4>
<p><a href="https://www.inc.com/carmine-gallo/how-to-start-a-successful-negotiation-in-2-words.html">How to Start a Successful Negotiation in 2 Words</a> <output>(Carmine Gallo)</output></p>
<p><a href="http://matthewrocklin.com/blog/work/2020/07/13/brevity">Write to a short attention span Brevity is the soul of wit</a> <output>(Matthew Rocklin)</output></p>
<p><a href="https://www.davidfischer.name/2017/01/python-command-line-apps/">Python Command Line Apps</a> <output>(David Fischer)</output></p>
<p><a href="https://www.inc.com/jeff-haden/5-words-that-make-your-emails-sound-indecisive-wishy-washy.html">5 Words That Make Your Emails Sound Indecisive and Wishy-Washy</a> <output>(Jeff Haden)</output></p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Mid-year review of my goals for 2020]]></title><description><![CDATA[Here's a review of how are going on my goals for 2020.]]></description><link>http://manuelviera.com/blog/mid-year-review-of-my-goals-for-2020/</link><guid isPermaLink="false">5f2566f9ba2e251b6d63a742</guid><category><![CDATA[self-tracking]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Wed, 15 Jul 2020 17:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1544819667-9bfc1de23d4e?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1544819667-9bfc1de23d4e?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Mid-year review of my goals for 2020"><p>At the beginning of 2020, I <a href="https://manuelviera.com/blog/list-of-goals-for-2020/">released a list of my goals</a> for the next 365 days. And now, here's a middle year review of <a href="https://manuelviera.com/blog/list-of-goals-for-2020/">the 17 goals I set for this year</a>.</p>
<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><ul>
<li>
<p><strong>Improve my English skills</strong>.<br>
On track: I started taking classes at a local English academy at the beginning of February. I also recovered my account at <a href="https://www.babbel.com/">Babbel</a> and started studying here too. At the end of April, I discovered <a href="https://w.8belts.com/">8Belts</a>. So I started an eight-month course to improve my speaking fluency with them too.</p>
</li>
<li>
<p><strong><s>Travel more</s></strong>.<br>
Failed: due to Covid-19, I'm not traveling this year.</p>
</li>
<li>
<p><strong>Read at least 1 book a month</strong>.<br>
On track: I've already read 10 books this year.</p>
</li>
<li>
<p><strong><s>Swim more kms than 2019</s></strong>.<br>
Failed: due to Covid-19, I stopped swimming. My last swim training was on the 9th of March, 2020.</p>
</li>
<li>
<p><strong>Get back to bodyweight workouts</strong>.<br>
Behind target: due to Covid-19, I'm doing outdoor sports since I finished my personal lockdown. I'm trying to add this kind of workouts but I'm not being consistent weekly.</p>
</li>
<li>
<p><strong><s>Join some obstacle races</s></strong>.<br>
Failed: due to Covid-19, all races were canceled. The one I joined was Spartan Virtual Race which was adapted to take part at home.</p>
</li>
<li>
<p><strong><s>Learn French. Look for some classes</s></strong>.<br>
Failed: Postponed at least till next year.</p>
</li>
<li>
<p><strong>Have more fun time (playing videogames, etc)</strong>.<br>
On track: I'm playing one video game a month.</p>
</li>
<li>
<p><strong>Reduce procrastination</strong>.<br>
On track: Working on it. I still procrastine but less than before. I'm tracking personal metrics to push myself do what I have to do.</p>
</li>
<li>
<p><strong>Improve wellbeing &amp; mental health</strong>.<br>
Behind target: I started doing meditation since March, but I reduced the number of sessions in June and July. I want to get back to it as a daily routine.</p>
</li>
<li>
<p><strong>Start doing yoga 2 or 3 times a week</strong>.<br>
Behind target: I started practicing Yoga in March. I was motivated to do a Yoga session every day in the morning as part of my morning routine. But in June I decreased the number of sessions till zero in July. I want to recover it again as my morning or evening routine.</p>
</li>
<li>
<p><strong>Help people</strong>.<br>
Behing target: I was thinking about doing volunteering. Instead of this, I donated money during the pandemic.</p>
</li>
<li>
<p><strong><s>TheRoot: make a website and publish there my photos</s></strong>.<br>
Removed: I decided not put efforts on it.</p>
</li>
<li>
<p><strong>Get back to blogging in this blog</strong>.<br>
Behind target: I migrated this blog from Hugo to Ghost again. And I'm starting blogging again, but not as much as I'd like.</p>
</li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Media consumption in June 2020]]></title><description><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Read 1 books <output>(347 min)</output> and 9 articles.</li>
<li>Watched 1 movies <output>(115 min)</output>, 15 TV episodes <output>(1155 min)</output> and 0 talks <output>(0 min)</output>.</li>
<li>Listened to 16 podcasts episodes <output>(617 min)</output>.</li>
<li>Played 2 video games <output>(149 min)</output>.</li>
</ul>
<h4 id="books">Books</h4>
<p><a href="https://www.amazon.es/Do-Today-Procrastination-Productivity-Meaningful-ebook/dp/B07DRP1Q5W/">Do It Today</a> <output>(Darius Foroux)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 0-100%</output></p>
<h4 id="recommendedarticles">Recommended articles</h4>
<p><a href="https://medium.com/@sawyerh/how-i-export-process-and-resurface-my-kindle-highlights-addc9de9af1a">How I export, analyze,</a></p>]]></description><link>http://manuelviera.com/blog/media-consumption-in-june-2020/</link><guid isPermaLink="false">5f29c3a34501b8255139fcc1</guid><category><![CDATA[self-tracking]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Mon, 06 Jul 2020 18:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Read 1 books <output>(347 min)</output> and 9 articles.</li>
<li>Watched 1 movies <output>(115 min)</output>, 15 TV episodes <output>(1155 min)</output> and 0 talks <output>(0 min)</output>.</li>
<li>Listened to 16 podcasts episodes <output>(617 min)</output>.</li>
<li>Played 2 video games <output>(149 min)</output>.</li>
</ul>
<h4 id="books">Books</h4>
<p><a href="https://www.amazon.es/Do-Today-Procrastination-Productivity-Meaningful-ebook/dp/B07DRP1Q5W/">Do It Today</a> <output>(Darius Foroux)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 0-100%</output></p>
<h4 id="recommendedarticles">Recommended articles</h4>
<p><a href="https://medium.com/@sawyerh/how-i-export-process-and-resurface-my-kindle-highlights-addc9de9af1a">How I export, analyze, and resurface my Kindle highlights</a> <output>(Sawyer Hollenshead)</output></p>
<p><a href="https://www.imore.com/how-i-use-shortcuts-automations-make-life-run-more-smoothly">How I use Shortcuts automations to make life run more smoothly</a> <output>(Joseph Keller)</output></p>
<p><a href="https://blog.cloudflare.com/why-is-there-a-v-in-sigsegv-segmentation-fault/">Why is there a &quot;V&quot; in SIGSEGV Segmentation Fault?</a> <output>(Marek Majkowski &amp; David Wragg)</output></p>
<p><a href="https://www.inc.com/jessica-stillman/your-emails-are-36-percent-more-likely-to-get-a-reply-if-you-close-them-this-way.html">Your Emails Are 36 Percent More Likely to Get a Reply If You Close Them This Way</a> <output>(Jessica Stillman / Inc.com)</output></p>
<h4 id="recommendedvideogames">Recommended video games</h4>
<p><a href="https://www.amazon.es/The-Last-of-us-Hits/dp/B07FF8XJWT/">The Last of Us: Remastered</a> <output>(Naughty Dog)</output></p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Media consumption in May 2020]]></title><description><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Read 2 books <output>(222 min)</output> and 7 articles.</li>
<li>Watched 0 movies <output>(0 min)</output>, 0 TV episodes <output>(0 min)</output> and 6 talks <output>(1373 min)</output>.</li>
<li>Listened to 0 podcasts episodes <output>(0 min)</output>.</li>
<li>Played 3 video games <output>(592 min)</output>.</li>
</ul>
<h4 id="books">Books</h4>
<p><a href="https://www.amazon.es/THINK-STRAIGHT-Change-Thoughts-English-ebook/dp/B077NJWFR3/">Think Straight</a> <output>(Darius Foroux)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 0-100%</output></p>
<p><a href="https://www.amazon.es/Mi-cuaderno-estoico-prosperar-control-ebook/dp/B07VN9SL4M/">Mi cuaderno estoico</a> <output>(Massimo Pigliucci)</output><br>
▓░░░░░░░░░░░░░░ <output>Progress: 0-7%</output></p>]]></description><link>http://manuelviera.com/blog/media-consumption-in-may/</link><guid isPermaLink="false">5f26defaba2e251b6d63a7a1</guid><category><![CDATA[self-tracking]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Wed, 03 Jun 2020 22:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Read 2 books <output>(222 min)</output> and 7 articles.</li>
<li>Watched 0 movies <output>(0 min)</output>, 0 TV episodes <output>(0 min)</output> and 6 talks <output>(1373 min)</output>.</li>
<li>Listened to 0 podcasts episodes <output>(0 min)</output>.</li>
<li>Played 3 video games <output>(592 min)</output>.</li>
</ul>
<h4 id="books">Books</h4>
<p><a href="https://www.amazon.es/THINK-STRAIGHT-Change-Thoughts-English-ebook/dp/B077NJWFR3/">Think Straight</a> <output>(Darius Foroux)</output><br>
▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓ <output>Progress: 0-100%</output></p>
<p><a href="https://www.amazon.es/Mi-cuaderno-estoico-prosperar-control-ebook/dp/B07VN9SL4M/">Mi cuaderno estoico</a> <output>(Massimo Pigliucci)</output><br>
▓░░░░░░░░░░░░░░ <output>Progress: 0-7%</output></p>
<h4 id="recommendedarticles">Recommended articles</h4>
<p><a href="https://ohdear.app/blog/resolving-the-addtrust-external-ca-root-certificate-expiration">Resolving the AddTrust External CA Root certificate expiration</a> <output>(Mattias Geniar)</output></p>
<p><a href="https://www.usenix.org/sites/default/files/conference/protected-files/lisa19_maheshwari.pdf">Linux Productivity Tools</a> <output>(Ketan M.)</output></p>
<p><a href="https://thenewstack.io/bare-metal-in-a-cloud-native-world/">Bare Metal in a Cloud Native World</a> <output>(Alex Ellis/The New Stack)</output></p>
<h4 id="recommendedtalk">Recommended Talk</h4>
<p><a href="https://www.youtube.com/watch?v=Avcligc5Cjo">The 8 Belts Method | TEDxCibeles</a> <output>(Anxo Pérez)</output></p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[List of goals for 2020]]></title><description><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Improve my English skills.<br>
This is <mark>my number one goal for this year</mark>. I want to start taking English classes.</li>
<li>Travel more.<br>
Make plans over calendar. Take WowTrips (or similar) into account for weekend trips.</li>
<li>Read at least 1 book a month.</li>
<li>Swim more kms than 2019.</li>
<li>Get back to</li></ul>]]></description><link>http://manuelviera.com/blog/list-of-goals-for-2020/</link><guid isPermaLink="false">5f251ec4ba2e251b6d63a6f4</guid><category><![CDATA[self-tracking]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Mon, 06 Jan 2020 23:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><ul>
<li>Improve my English skills.<br>
This is <mark>my number one goal for this year</mark>. I want to start taking English classes.</li>
<li>Travel more.<br>
Make plans over calendar. Take WowTrips (or similar) into account for weekend trips.</li>
<li>Read at least 1 book a month.</li>
<li>Swim more kms than 2019.</li>
<li>Get back to bodyweight workouts.</li>
<li>Join some obstacle races.</li>
<li>Learn French. Look for some classes.</li>
<li>Improve wellbeing &amp; mental health.</li>
<li>Have more fun time (playing videogames, etc).</li>
<li>Reduce procrastination.</li>
<li>Read more tech articles every week.</li>
<li>Start doing meditation.</li>
<li>Start doing yoga 2 or 3 times a week.</li>
<li>Help people.</li>
<li>TheRoot: make a website and publish there my photos.</li>
<li>Get back to blogging in this blog.</li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Compartiendo ficheros con GlusterFS]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>Cuando aparece la necesidad de escalar una aplicación web, o cualquier otro servicio, en Internet; también aparecen nuevos problemas a resolver que antes incluso ni habíamos reparado en ellos. Uno de estos problemas es <strong>la compartición de ficheros</strong> entre servidores.</p>
<p>En mi opinión, a día de hoy éste sigue siendo</p>]]></description><link>http://manuelviera.com/blog/compartiendo-ficheros-con-glusterfs-2/</link><guid isPermaLink="false">5ee79a5311a5bb564c241b61</guid><category><![CDATA[tech]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Tue, 02 Aug 2016 00:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1569235186275-626cb53b83ce?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1569235186275-626cb53b83ce?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Compartiendo ficheros con GlusterFS"><p>Cuando aparece la necesidad de escalar una aplicación web, o cualquier otro servicio, en Internet; también aparecen nuevos problemas a resolver que antes incluso ni habíamos reparado en ellos. Uno de estos problemas es <strong>la compartición de ficheros</strong> entre servidores.</p>
<p>En mi opinión, a día de hoy éste sigue siendo un dolor de cabeza para muchos Sysadmins o Systems Architects. Hay muchas formas de compartir ficheros entre servidores como NFS, S3FS, FileConveyor, un crontab con un rsync entre servidores. Hay muchas soluciones, algunas mejores y otras peores; pero hoy quería compartir la que hasta ahora creo que puede ser una buena solución para compartir ficheros, usando <strong>GlusterFS</strong>.</p>
<p><a href="https://www.glusterfs.org">GlusterFS</a> es un sistema de ficheros escalable en red, con el que poder crear soluciones de almacenamiento distribuidos por la red y de gran capacidad. Ni que decir tiene que <strong>GlusterFS</strong> es software libre.</p>
<h2 id="antesdeempezar">Antes de empezar</h2>
<p>Normalmente en los despliegues que hacemos en AWS en <a href="http://crononauta.com">Crononauta</a>, siempre utilizamos un mínimo de un par de instancias EC2 para el sistema de almacenamiento en red con <strong>GlusterFS</strong>. Además, a cada una de estas dos instancias EC2, hacemos <em>attach</em> de un disco EBS donde almacenaremos los ficheros en el clúster de ficheros en red. Esto nos permite tener <strong>redundancia</strong> en los datos, <strong>alta disponibilidad</strong> y <strong>escalabilidad horizontal</strong> en el servicio. Con lo cual, tendremos un par de instancias que mantienen en clúster de almacenamiento actuando como GlusterFS Server y por otro lado, tendremos los clientes de GlusterFS que montarán este volumen compartido por la red.</p>
<p>Como detalle, en <strong>Crononauta</strong> siempre usamos Debian como distribución, en este caso contamos con una Debian 8 (Jessie), aunque es totalmente aplicable a cualquier distribución basada en Debian como Ubuntu y/o derivadas.</p>
<p>Una vez tenemos esto, podemos empezar a trabajar... ;-)</p>
<h2 id="particionandolosdiscos">Particionando los discos</h2>
<p>Utilizaremos <strong>XFS</strong> como sistema de ficheros para el volumen compartido en red. Por lo que necesitaremos instalar las utilidades para trabajar con XFS, si no las tenemos ya instaladas.</p>
<pre><code>apt-get install xfsprogs
</code></pre>
<p>El siguiente paso será crear una partición en el volumen, en mi caso es <code>/dev/xvdf</code>. Usaremos <code>fdisk</code> para ello:</p>
<pre><code>fdisk /dev/xvdf
</code></pre>
<p>y una vez en la shell interactiva de <code>fdisk</code>, teclearemos:</p>
<ol>
<li><code>n</code> para crear una nueva partición. No necesitamos especificar nada más, así que los siguientes datos que pide podemos usar los valores por defecto que ofrece <code>fdisk</code>, asi que pulsaremos <code>Intro</code> hasta finalizar. Una vez hecho esto, seguiremos dentro de la shell interactiva de <code>fdisk</code>, y habremos creado una partición primaria que ocupa todo el espacio del volumen.</li>
<li><code>w</code> indicando que queremos escribir esta definición de partición en el disco y hacerla efectiva.</li>
</ol>
<p>Ya tenemos la partición en el volumen, así que ahora la formatearemos y la añadiremos a nuestro <code>/etc/fstab</code> para montarla en cada arranque del sistema. Seguiremos los siguientes pasos:</p>
<pre><code>mkfs.xfs -i size=512 /dev/xvdf1
mkdir -p /export/brick1
echo &quot;/dev/xvdf1 /export/brick1 xfs defaults 1 2&quot;  &gt;&gt; /etc/fstab
mount -a &amp;&amp; mount
</code></pre>
<h2 id="instalandoglusterfs">Instalando GlusterFS</h2>
<p>Ya tenemos el volumen preparado para GlusterFS, ahora instalaremos el servicio.</p>
<pre><code>apt-get update
apt-get install glusterfs-server glusterfs-client glusterfs-common
</code></pre>
<p>Importante realizar este paso en aquellas instancias / servidores que vayan a actuar como un GlusterFS Server.</p>
<p>Lo siguiente que haremos será configurar nuestro fichero <code>/etc/hosts</code> para definir unos nombres DNS para nuestros GlusterFS Servers. También es posible hacerlo con un DNS interno. Si vuestros servidores, como en el caso de AWS EC2, contáis con IPs privadas, mejor usar esas. Si no, podéis usar las IPs pública.</p>
<p>Definiremos algo como lo siguiente en <code>/etc/hosts</code>:</p>
<pre><code>xxx.xxx.xxx.xxx    gfs01.example.com
xxx.xxx.xxx.xxx    gfs02.example.com
</code></pre>
<h2 id="unanilloparagobernarlosatodos">Un anillo para gobernarlos a todos</h2>
<p>Ya tenemos GlusterFS preparado para ser configurado. Ahora tendremos que configurar el <em>anillo de confianza</em> entre ambos servidores GlusterFS Server. Para ello serán necesarios los siguientes pasos:</p>
<ol>
<li>
<p>Desde <code>gfs01.example.com</code>:</p>
<pre><code> gluster peer probe gfs02.example.com
</code></pre>
</li>
<li>
<p>Desde <code>gfs02.example.com</code>:</p>
<pre><code> gluster peer probe gfs01.example.com
</code></pre>
</li>
</ol>
<p>Es <strong>muy importante</strong> que haya conectividad entre ambos servidores, en caso contrario, los comandos anteriores fallarán. Si estás en AWS, asegúrate de tener bien configurado el <strong>Security Group</strong> para ambas instancias de storage.</p>
<p>Si todo ha ido bien, tendremos el pool de confianza funcionando, así que lo siguiente será definir el volumen compartido. Usaremos la siguiente instrucción desde uno de los servidores GlusterFS:</p>
<pre><code>gluster volume create gv0 replica 2 gfs01.example.com:/export/brick1/&lt;volume-name&gt; gfs02.example.com:/export/brick1/&lt;volumen-name»
</code></pre>
<p>Por último, iniciaremos el volumen que justo acabamos de crear:</p>
<pre><code>gluster volume start gv0
</code></pre>
<p>Como detalle, podemos ver información sobre el volumen con la siguiente instrucción:</p>
<pre><code>gluster volume info
</code></pre>
<p>Llegados a este punto, el cluster de almacenamiento debe estar totalmente operativo. Si queremos hacer una prueba, es posible crear el punto de montaje hacia el volumen compartido y probar si se replican correctamente los ficheros. Crearemos el punto de montaje en <code>gfs01.example.com</code> de la siguiente forma:</p>
<pre><code>mount -t glusterfs localhost:/gv0 /mnt
</code></pre>
<p>Ahora crearemos ficheros para comprobar si el funcionamiento de GlusterFS es correcto. Con la siguiente instrucción crearemos diez ficheros vacíos en el punto de montaje previamente creado:</p>
<pre><code>touch /mnt/test-file{1..10}.txt
</code></pre>
<p>Si GlusterFS funciona correctamente, debemos poder ver estos mismos ficheros en <code>gfs02.example.com</code> en el directorio <code>/export/brick1/&lt;volume-name&gt;</code>.</p>
<h2 id="configurandolosclientes">Configurando los clientes</h2>
<p>Nos falta muy poco para terminar, ya sólo nos falta configurar los clientes de GlusterFS. Necesitaremos tener instalado el cliente de GlusterFS <code>glusterfs-client</code> si no lo tenemos instalado.</p>
<pre><code>apt-get install glusterfs-client
</code></pre>
<p>Hecho esto, podremos probar a montar el volumen compartido por la red, y si todo va bien debemos ver los ficheros de prueba creados previamente.</p>
<pre><code>mount -t glusterfs gfs01.example.com:/gv0 /mnt
</code></pre>
<p>Por último, necesitaremos un script <code>/etc/init.d/glusterfs-mount</code> que se encargue de montar el volumen compartido. En mi caso suelo utilizar el siguiente script:</p>
<pre><code>#! /bin/bash
### BEGIN INIT INFO
# Provides:          glusterfs-mount
# Required-Start:    $remote_fs $syslog
# Required-Stop:     $remote_fs $syslog
# Default-Start:     2 3 4 5 
# Default-Stop:      0 1 6 
# Short-Description: Start daemon at boot time
# Description:       Enable service provided by daemon.
### END INIT INFO
#

MOUNTPOINT=&quot;/var/www/shared&quot;
GLUSTERFS_SERVER=&quot;gfs01.example.com&quot;
GLUSTERFS_VOLUME=&quot;gv0&quot;

# Some things that run always at boot
mount -t glusterfs $GLUSTERFS_SERVER:/$GLUSTERFS_VOLUME $MOUNTPOINT
#
# Uncomment this line if you need to start Apache after mount glusterFS volume
# service apache2 start
#
# Carry out specific functions when asked to by the system
case &quot;$1&quot; in
  start)
    echo &quot;Mounting glusterfs volumes &quot;
    mount -t glusterfs $GLUSTERFS_SERVER:/$GLUSTERFS_VOLUME $MOUNTPOINT
    ;;
  stop)
    echo &quot;Unmount glusterfs volumes&quot;
    umount $MOUNTPOINT
    ;;
  *)
    echo &quot;Usage: /etc/init.d/glusterfs-mount {start|stop}&quot;
    exit 1
    ;;
esac
exit 0
</code></pre>
<p>Ya solo nos queda dar permisos de ejecución a nuestro script y configurarlo para que se ejecute durante el inicio del sistema:</p>
<pre><code>chmod +x /etc/init.d/glusterfs-mount
update-rc.d glusterfs-mount defaults
</code></pre>
<h3 id="faq">FAQ</h3>
<ul>
<li><strong>Q:</strong> No puedo crear el anillo de confianza. Los comandos <code>gluster peer probe</code> terminan fallando con un timeout ¿Qué ocurre?</li>
</ul>
<ul>
<li><strong>A:</strong> Es muy probable que sea un problema de conectividad entre ambos GlusterFS Servers. Revisa si hay algún firewall entre ellos que pueda estar bloqueando conexiones TCP y UDP<br>
entre ellos. Puedes ver los puertos abiertos con <code>netstat -ntlp</code>.</li>
</ul>
<p>Si estás en AWS, asegúrate que el <strong>Security Group</strong> que usan ambas instancias tienen permitidos los accesos a puerto TCP y UDP entre ellos.</p>
<ul>
<li><strong>Q:</strong> No puedo montar el volumen compartido desde las instancias que actuan como clientes. El comando <code>mount</code> responde con <code>mount failed</code>. ¿Qué puede estar ocurriendo?</li>
</ul>
<ul>
<li><strong>A:</strong> Al igual que con los servidores GlusterFS, revisa que las instancias clientes tienen conectividad con los servidores. GlusterFS suele abrir un rango de puertos para cada volumen exportado (gv0, gv1, gv2, etc). Es recomendable permitir todo el tráfico TCP y UDP entre las instancias clientes y servidor. De otra forma es probable que alguna vez tengamos problemas al montar los volumenes.</li>
</ul>
<ul>
<li><strong>Q:</strong> Sigo sin poder crear el punto de montaje desde las instancias clientes. El comando <code>mount</code> indica que hubo un problema. La conectividad entre cliente y servidor de GlusterFS es correcta ¿Qué problema puede haber?</li>
</ul>
<ul>
<li><strong>A:</strong> Es muy común que las versiones de las distribuciones entre cliente y servidor difieran. Si esto es así, es muy probable que la versión de <code>glusterfs-client</code> difiera de la versión de <code>glusterfs-server</code>. En este caso, es muy probable que no podamos montar el volumen compartido con el driver <code>glusterfs</code>.</li>
</ul>
<p>GlusterFS permite montar los volumenes con el driver de NFS. En este tipo de situaciones es normal recurrir al driver de NFS para crear el punto de montaje. Para ello se necesita tener instalado <code>nfs-common</code> y crear el punto de montaje con la siguiente instrucción:</p>
<pre><code>mount -t nfs gfs01.example.com:/gv0 /var/www/shared
</code></pre>
<ul>
<li><strong>Q:</strong> ¿Por qué crear un script en <code>/etc/init.d</code> pudiendo configurar el montaje en el fichero <code>/etc/fstab</code>?</li>
</ul>
<ul>
<li><strong>A:</strong> Sí, es posible configurar el punto de montaje en <code>/etc/fstab</code>, pero a diferencia del resto de punto de montajes, en este caso se trata de un volumen compartido por la red. Es muy probable que cuando se monten los volumenes de <code>/etc/fstab</code>, aún no esté disponible la red en el sistema, con lo cual el montaje no solo fallará, sino que además es posible que ralentize el arranque del sistema hasta que el intento de montar el volumen por la red de un Timeout. Por eso es más fiable hacerlo con un script en <code>init.d</code>, una vez la red ya esté disponible.</li>
</ul>
<p>Creo que esto es todo. ¿Encontráis algún otro problema? ¡Dejadlo en los comentarios!<br>
Saludos.</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[AWS Summit Barcelona 2015]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>No suelo viajar mucho por trabajo pero, desde que trabajo en Crononauta, siempre subo a Barcelona varias veces al año. Y además de trabajar, esta vez hemos aprovechado para asistir al <strong>AWS Summit 2015 Barcelona</strong>.</p>
<p>El evento de Amazon Web Services, tuvo lugar durante todo la jornada del Jueves 5</p>]]></description><link>http://manuelviera.com/blog/aws-summit-barcelona-2015/</link><guid isPermaLink="false">5ee798b111a5bb564c241b3a</guid><category><![CDATA[tech]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Thu, 12 Nov 2015 00:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>No suelo viajar mucho por trabajo pero, desde que trabajo en Crononauta, siempre subo a Barcelona varias veces al año. Y además de trabajar, esta vez hemos aprovechado para asistir al <strong>AWS Summit 2015 Barcelona</strong>.</p>
<p>El evento de Amazon Web Services, tuvo lugar durante todo la jornada del Jueves 5 de Noviembre en Fira de Barcelona, Montjuïc. Nunca había estado en Fira Barcelona, con lo cual me impresionó el edificio, el salon de actos principal y toda la organización del evento. Especialmente el catering, que me pareció muy bueno. La calidad de la comida era bastante buena, y en ningún momento faltó de nada. En todo momento había snacks, zumos, agua, café y bollería.</p>
<p>En cuanto al evento, el AWS Summit Barcelona fue inaugurado por Guillem Veiga, Head of AWS en Iberia, con una breve introducción de todo lo que íbamos a poder ver durante la jornada.</p>
<h3 id="awsreinvent2015">AWS re:Invent 2015</h3>
<p>Luego vino <strong>Jeff Barr</strong>, el Chief Evangelist de AWS; que muchos lo conocemos ser quien administra y publica en el blog de AWS. Quién mejor que él, que lleva 13 años trabajando en AWS, para contarnos cómo ha ido evolucionando AWS a lo largo de estos años. Entre otras cosas nos contaba cómo en 2007 AWS sólo contaba con tres servicios (EC2, RDS y S3), y actualmente en 2015 cuentan con más de 50 servicios, operando en 11 regiones diferentes. Jeff fue dando paso a ponencias como la de <strong>Luis Bosque</strong> de <strong>CartoDB</strong>, que nos explicó cómo funciona CartoDB, el volumen de datos que manejan y por qué decidieron migrar a AWS; o los chicos de <strong>BEEVA</strong> que nos enseñaron su proyecto de Big Data con algoritmos de Machine Learning para ofrecer información útil a sus clientes sobre ventas de artículos por zonas, o incluso ventas de productos relacionados con su sector.</p>
<h3 id="awssecurity">AWS Security</h3>
<p>A continuación vino <strong>Bill Murray</strong>, pero no el actor de cine, sino el director de AWS Security. Lo que más me llamó la atención de su ponencia fue la presentación de un nuevo producto llamado <strong>Amazon Inspector</strong> que, de momento, está en &quot;preview&quot; y sólo está disponible en la región US West (Oregon).</p>
<p><strong>Amazon Inspector</strong> te permite analizar el comportamiento de las aplicaciones que ejecutas en AWS y te ayuda a identificar fallos potenciales de seguridad.</p>
<p>Básicamente te permite instalar un agente en las instancias EC2, para poder<br>
ejecutar una serie de checks que te ayudarán a comprobar la seguridad de tu<br>
plataforma. Bill nos enseñó algunos checks básicos como el login SSH con root.</p>
<p>Una vez se ejecutan estos checks, te permite realizar un análisis general de la seguridad de la plataforma.</p>
<p>De momento este servicio está algo limitado, porque<br>
los agentes sólo pueden ser instalados en Amazon Linux AMI 2015.03 (o<br>
posteriores) o Ubuntu Server 14.04 LTS, de momento.</p>
<h3 id="todoloquenecesitassabersobreautoscaling">Todo lo que necesitas saber sobre Autoscaling</h3>
<p>Seguro que si has trabajado ya sobre AWS, esto ya te suene de algo, o al menos ese era mi caso. Realmente el tema de Autoscaling es un servicio, sin coste adicional, que ofrece AWS dentro de EC2; y que permite que tu infraestructura escale horizontalmente, siempre y cuando esté preparada para ello, claro está.</p>
<p>Realmente, que una plataforma pueda escalar horizontalmente, no sólo depende de que configuremos o no el Autoscaling en EC2. Para que una plataforma pueda escalar horizontalmente debe estar bien diseñada, tanto a nivel de sistemas, separando los servicios / stack de software de forma inteligente; como a nivel de código, porque la aplicación también debe estar preparada para escalar.</p>
<p>Si tenemos bien resuelta esta parte, AWS nos proporciona los componentes<br>
necesarios para escalar nuestra aplicación de forma más o menos sencilla,<br>
configurando los siguientes componentes:</p>
<ul>
<li>
<p><strong>Launch Configuration</strong>: permite definir la &quot;template&quot; de instancia EC2 que vamos a arrancar, en caso de que necesitemos auto escalar. Podremos definir qué AMI queremos usar, almacenamiento,<br>
security group, etc.</p>
</li>
<li>
<p><strong>Auto Scaling Group</strong>: permite crear un grupo de Autoscaling basado en un Launch Configuration.<br>
Básicamente podemos definir el número mínimo de instancias en el grupo de auto escalado, número máximo de instancias, zonas de disponibilidad sobre la que vamos a operar, si queremos añadir las instancias bajo un balanceador o ELB (Elastic Load Balancer), etc.</p>
</li>
<li>
<p><strong>CloudWatch Alarms</strong>: <strong>CloudWatch</strong> es el servicio de monitorización de AWS. Es un servicio que no supone coste adicional, siempre que no activemos el <em>Detailed Monitoring</em>. Nos permitirá monitorizar nuestro Autoscaling Group, y en base a las alertas que configuremos, nuestra plataforma será capaz de lanzar nuevas instancias cuando sea necesario. Por ejemplo, podremos arrancar un par de instancias más en el caso de que el uso de CPU del grupo de Autoscaling supere el 80% durante 10 minutos, y volver a eliminarlas cuando la CPU del Autoscaling group baje del<br>
40% durante 15 minutos.</p>
</li>
</ul>
<p>Últimamente he trabajado mucho con esto, así que seguramente le dedique un post donde pueda entrar más en detalle.</p>
<h3 id="gestionandocontainersaescala">Gestionando Containers a Escala</h3>
<p>En esta Live Demo se presentaba el servicio <strong>EC2 Container Service</strong>, que<br>
permite desplegar, gestionar y escalar contenedores <strong>Docker</strong> donde ejecutar aplicaciones, servicios o simplemente scripts para realizar cálculos.</p>
<p>En mi caso aún no tengo muchos conocimientos sobre Docker, pero si has trabajado con él, te facilitará la gestión de clusters de contenedores en varias instancias EC2. Aunque si esto no te gusta siempre puedes montar Docker desde cero en una instancia EC2.</p>
<p>La demo que hizo el ponente era desplegar una página web sencilla dentro de un cluster Docker. Podéis desplegar esta aplicación de ejemplo desde el Dashboard de ECS.</p>
<p><strong>ECS</strong> básicamente te abstrae de todo lo referente a la administración de Docker, y te permite definir un cluster en unos cuantos pasos sencillos. Durante estos pasos puedes elegir la memoria asignada a cada contenedor, mapeo de puertos que se suele hacer en Docker, usar un ELB (balanceador) para el cluster, e incluso definir la cantidad y tipo de instancias EC2 en las que queremos alojar el cluster.</p>
<p>En mi caso me apunto estudiar este servicio, porque la verdad es que los<br>
conocimientos que tengo de él son bastante básicos.</p>
<h3 id="desplieguecontinuoenaws">Despliegue Continuo en AWS</h3>
<p>En esta Live Demo se presentaban tres servicios: <strong>AWS CodeCommit</strong>, <strong>AWS<br>
CodePipeline</strong> y <strong>AWS CodeDeploy</strong>. Estos tres servicios están dentro de la categoría de <em>Developers Tools</em> y permiten alojar código fuente, Integración Continua y deploy de código, respectivamente. A decir verdad me perdí la demo de los dos primeros, pero pude asistir a la de <strong>AWS CodeDeploy</strong>.</p>
<p><strong>CodeDeploy</strong> permite desplegar código fuente de forma relativamente sencilla. En muy resumidas cuentas, este servicio se basa en tener<br>
un agente ejecutándose en cada una de las instancias y, una vez configurado un <em>Deployment Group</em>, es posible especificar una URL hacía un fichero zip alojado en un Bucket de S3 o repositorio Github. Mediante un fichero de configuración, que debe ir dentro del repositorio de código, podremos indicar al agente dónde desplegar el código, o incluso ejecutar comandos tras realizar el deploy, en un <em>post-hook</em>.</p>
<p><strong>CodeDeploy</strong> permite configurar cuándo un deployment se considera &quot;ok&quot; o &quot;fallido&quot;.</p>
<ul>
<li><strong>One at a Time</strong>: se considera un deployment fallido si falla en al menos una de las instancias del <em>Deployment Group</em>.</li>
<li><strong>Half at a Time</strong>: se considera fallido si falla en la mitad de las instancias del <em>Deployment Group</em>.</li>
<li><strong>All at Once</strong>: se considera deployment fallido si falla en todas las instancias del <em>Deployment Group</em>.</li>
</ul>
<p>Quizás una de las cosas que no me convencen de CodeDeploy es que se necesita tener un agente con un puerto abierto en cada instancia, lo cual puede añadir un punto de fallo en cuanto a seguridad; y que, si no estoy equivocado, no tiene opción de rollback. Si algo va mal, la única opción es volver a desplegar una versión del código que sepamos que funciona bien.</p>
<h3 id="utilizandospotinstancesdeamazonec2">Utilizando Spot Instances de Amazon EC2</h3>
<p>Las spot instances han avanzado mucho desde que fueron introducidas por primera vez. Normalmente el precio las instancias EC2, al margen del tipo de instancia que se elija con más o menos recursos; varia en función del <em>modelo de compra</em> de la instancia. Puede ser <em>On Demand</em>, <em>Reserved</em>, o <em>Spot Instances</em></p>
<p>Las instancias <em>On Demand</em> son las de uso más común. Simplemente cada tipo de instancia en la modalidad de <em>On Demand</em> tienen un precio fijo. Si arrancas una instancia <em>On Demand</em> sabes que el precio que AWS te cobra es el especificado en la documentación, y el coste total dependerá del tiempo que esté esa instancia en modo <em>Running</em>.</p>
<p>Pero también existe la modalidad de <em>Spot Instances</em>. Para no hacer muy pesada la explicación, básicamente consiste en fijar el precio que te gustaría pagar por un tipo de instancia, y en el momento en que el precio de mercado esté por debajo del precio que hayas establecido, podrás arrancar instancias de ese tipo a ese precio. Es como jugar a bolsa, cuando las acciones caigan por debajo de un umbral de dinero, compro acciones.</p>
<p>La modalidad <em>Spot Instances</em> es muy llamativa a la hora de aplicarla con un Autoscaling Group, pues podríamos conseguir ahorros bastante significativos, arrancando <em>Spot Instances</em> cuando el precio caiga, y mientras tanto seguir usando <em>On Demand</em>.</p>
<h3 id="amazonelasticfilesystem">Amazon Elastic Filesystem</h3>
<p><strong>Amazon Elastic Filesystem</strong> es uno de los servicios que llevo esperando mucho tiempo. De momento, no está disponible en Ireland pero espero que lo estrenen en Europa de aquí a unos meses.</p>
<p>Uno de los principales problemas a resolver cuando trabajas en una<br>
infraestructura con escalabilidad horizontal, es la compartición de ficheros entre instancias. Hasta ahora mucha gente se ha configurado su propio cluster NFS, GlusterFS, e incluso he llegado a ver soluciones que usan un Bucket S3 junto con <em>s3fs</em>, lo cual me parece muy arriesgado, porque se ha demostrado que no funciona muy bien. Precisamente esto es lo que viene a resolver <strong>EFS</strong>.</p>
<p>Al igual que con el resto de servicios, podremos abstraernos de la creación del cluster de ficheros y del storage de éste. En pocos minutos podemos contar con un punto de montaje con varios Terabytes y con una SLA muy alta. Este servicio realmente se basa en <em>NSFv4</em>. Estoy deseando poder probar este servicio en algún proyecto, hacer pruebas de carga y ver si realmente funciona tan bien como se espera, o si tendré que seguir usando mi propio cluster de GlusterFS para compartir ficheros entre instancias.</p>
<p>Y creo que esto es todo, la verdad es que mola mucho asistir a este tipo de<br>
eventos, porque no todo es resolver tickets, leer documentación, gestionar<br>
alertas y atender clientes. En este tipo de charlas siempre se abre un poco la mente, sobre todo escuchando las experiencias de los demás, en este caso con AWS.</p>
<p>En breve escribiré posts relacionados con Amazon Web Services, y espero poder entrar mucho más en detalle.</p>
<p>Un saludo!</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Y pasaron dos años ...]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>Y pasaron dos años. Que se dice pronto. Realmente aún no me creo que hayan<br>
pasado dos años sin escribir nada en el blog. Supongo que es algo que vas<br>
dejando por aquello de que trabajas mucho tiempo al día, y luego te faltan las ganas de sentarte enfrente del</p>]]></description><link>http://manuelviera.com/blog/y-pasaron-dos-anos/</link><guid isPermaLink="false">5ee648ca46e19912dcb41670</guid><category><![CDATA[offtopic]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Mon, 02 Nov 2015 00:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>Y pasaron dos años. Que se dice pronto. Realmente aún no me creo que hayan<br>
pasado dos años sin escribir nada en el blog. Supongo que es algo que vas<br>
dejando por aquello de que trabajas mucho tiempo al día, y luego te faltan las ganas de sentarte enfrente del portatil, otra vez, a seguir hablando de lo mismo.</p>
<p>No obstante, aunque no haya escrito en todo este tiempo, tengo que decir que no he estado &quot;ausente&quot;, al menos no del todo, sino que he estado en &quot;la sombra&quot;, apuntando ideas, probando y migrando a otros frameworks para bloguear, trabajando, y sobre todo aprendiendo. Siempre que entro aquí, me siento orgulloso, porque aunque no le he dedicado mucho tiempo últimamente, las visitas diarias no decaen. Y lo más importante, sigo recibiendo comentarios y preguntas en algunos posts. Con lo cual, esto me empuja a seguir con este proyecto. ¡Gracias!</p>
<p>Durante estos dos años he estado trabajando en Crononauta. La empresa donde<br>
trabajo actualmente, y en la que pretendo seguir durante más tiempo. Así quiero que sea de momento. Si recapacito un poco en todo este tiempo, creo que he crecido mucho, tanto como persona, como profesionalmente hablando.</p>
<p>Estoy satisfecho en este aspecto, porque creo que ahora soy capaz de proponer y de aplicar mejores soluciones y, sobre todo, más profesionales. Por este motivo, igual incorporo algunos posts que hablen sobre la toma de decisiones a la hora de aplicar soluciones a problemas.</p>
<p>Además he aprendido mucho, y sigo aprendiendo, sobre monitorización. O ¿cómo saber qué pasa dentro de cada servidor y cómo adelantarnos a posibles problemas? Seguramente también incorpore posts sobre este campo. Me parece muy interesante poder adelantarte a problemas, o cómo definir una estrategia de monitorización que te permita detectar o monitorizar problemas a tan bajo nivel como necesites.</p>
<p>También, de un año hacia acá, he aprendido muchisimo sobre Cloud, y en concreto estamos especializándonos en AWS (Amazon Web Services). Espero no volver a abandonar este blog durante un tiempo de nuevo, porque me gustaría compartir mis conocimientos de AWS. ¡Hay muchas cosas interesantes!</p>
<p>No me enrrollo más. Este post es un poco para &quot;romper el hielo&quot; y convencerme a mí mismo, de que tengo que dedicar parte de mi tiempo a exportar conocimiento aquí. Espero escribir pronto de nuevo.</p>
<p>¡Nos leemos!<br>
Manu.</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Instalar Solr en Jetty]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>Hace ya más de un mes que no pasaba por aquí más que para ver las estadísticas del blog; así que ya es hora de que me siente a escribir algo y compartir con el resto de internet.</p>
<p>Hoy vengo hablando, o escribiendo, sobre cómo instalar / montar una instancia de</p>]]></description><link>http://manuelviera.com/blog/instalar-solr-en-jetty/</link><guid isPermaLink="false">5ee647a546e19912dcb41657</guid><category><![CDATA[tech]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Mon, 29 Apr 2013 00:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>Hace ya más de un mes que no pasaba por aquí más que para ver las estadísticas del blog; así que ya es hora de que me siente a escribir algo y compartir con el resto de internet.</p>
<p>Hoy vengo hablando, o escribiendo, sobre cómo instalar / montar una instancia de Solr sobre Jetty, porque esta semana pasada me surgió la necesidad de montar una instancia y hemos tenido que pelear un poco para hacerlo, así que he decidido crear una receta muy simple para tenerlo funcionando rápidamente y siguiendo unos pasos muy sencillos. Pero empecemos por el principio...</p>
<!--more-->
<h2 id="quessolr">¿Qué es Solr?</h2>
<p><a href="http://lucene.apache.org/solr/">Solr</a> es la plataforma de búsqueda de código abierto del proyecto Apache Lucene. Es una plataforma de búsqueda muy popular y rápida; está escrita en Java y se ejecuta de forma independiente dentro de un servidor de aplicaciones como pueder ser <a href="http://tomcat.apache.org/">Tomcat</a> o <a href="http://www.eclipse.org/jetty/">Jetty</a>. Podéis encontrar mucha más información<br>
de Sorl en su <a href="http://lucene.apache.org/solr/">página oficial</a>.</p>
<h2 id="preparativos">Preparativos</h2>
<p>Antes de empezar con la instalación de Solr necesitamos tener instalados varios paquetes en nuestro sistema. En mi caso, y a la hora de escribir este post, estoy utilizando una distribución Ubuntu; y muchos pensaréis que es tan fácil como hacer un <code>apt-get install solr-jetty solr-common</code> pero mi necesidad surgió en una distribución Debian Squeeze, y no contaba con Solr en mi sistema de paquetería. De todas formas, este post tiene como fin poder instalar un Solr sin necesidad de utilizar el sistema de paquetería de nuestra distribución y poder utilizar una versión más nueva de Solr que la empaquetada en esta. Así que necesitaremos:</p>
<h3 id="java">Java</h3>
<p>Necesitaremos la máquina virtual de Java para poder ejecutar Solr dentro de<br>
nuestro contenedor de aplicaciones Jetty. Podemos buscar el paquete referente a <strong>openjdk</strong> en nuestra distribución. En mi caso, tengo instalado varios paquetes referentes a <strong>openjdk-7</strong>:</p>
<pre><code>$ dpkg -l |grep openjdk |awk '{print $2}'
openjdk-7-jre:amd64
openjdk-7-jre-headless:amd64
openjdk-7-jre-lib
</code></pre>
<p>Para comprobar que tenemos <strong>java</strong> correctamente instalado y<br>
conocer la versión que vamos a utilizar podemos ejecutar la siguiente<br>
instrucción:</p>
<pre><code>$ java -version
java version &quot;1.7.0_21&quot;
Java(TM) SE Runtime Environment (build 1.7.0_21-b11)
Java HotSpot(TM) 64-Bit Server VM (build 23.21-b01, mixed mode)
</code></pre>
<h3 id="jetty">Jetty</h3>
<p>Instalaremos el servidor de aplicaciones Jetty utilizando nuestro sistema de paquetería igual que hemos hecho con Java. Así que en distribuciones basadas en Debian utilizaremos la siguiente instrucción para su instalación:</p>
<pre><code>$ sudo apt-get install jetty libjetty-extra
</code></pre>
<h3 id="solr">Solr</h3>
<p>Como he comentado antes, en este caso no vamos a instalar Solr desde el sistema de paquetería, pues yo no tuve esa posibilidad y mi intención es compartir la forma de hacerlo de que exista un paquete en los repositorios, como era mi caso.</p>
<h4 id="descargarydescomprimirsolr">Descargar y descomprimir Solr</h4>
<p>Descargaremos y descomprimiremos la última versión disponible de Solr en este momento, la versión 4.2.1:</p>
<pre><code>$ cd /opt
$ sudo wget http://apache.rediris.es/lucene/solr/4.2.1/solr-4.2.1.tgz
$ tar xzf solr-4.2.1.tgz &amp;amp;&amp;amp; mv solr-4.2.1 solr
</code></pre>
<p>Crearemos el directorio <code>/usr/share/solr</code> y descomprimiremos dentro de él el contenido de <code>dist/solr-4.2.1.war</code>:</p>
<pre><code>$ sudo mkdir /usr/share/solr
$ cd /usr/share/solr
$ sudo unzip /opt/solr/dist/solr-4.2.1.war
</code></pre>
<p>Esta última instrucción descomprime los ficheros web de Solr en el directorio <code>/usr/share/solr</code> teniendo este el siguiente contenido:</p>
<pre><code>$ ls
admin.html  css  favicon.ico  img  js  META-INF  mgc  solr.xml  tpl  WEB-INF
</code></pre>
<h4 id="aadiendosolrajetty">Añadiendo Solr a Jetty</h4>
<p>Para instalar Solr como aplicación dentro de Jetty, crearemos un enlace<br>
simbólico de <code>/usr/share/solr</code> en <code>/usr/share/jetty/webapps</code>:</p>
<pre><code>$ sudo ln -s /usr/share/solr /usr/share/jetty/webbaps/solr
</code></pre>
<p><strong>NOTA:</strong> <code>/usr/share/jetty</code> es el directorio donde se encuentra instalado<br>
Jetty en nuestra distribución. Puedes consultarlo ejecutando: <code>dpkg -L jetty</code>.</p>
<p>Esto quiere decir que nuestra instancia de Solr va a ser accesible en<br>
<a href="http://localhost:8080/solr">http://localhost:8080/solr</a></p>
<h4 id="configurandojetty">Configurando Jetty</h4>
<p>Editaremos el fichero <code>/etc/default/jetty</code> a través del cual podremos modificar el comportamiento de éste sin necesidad de modificar sus ficheros de configuración XML.</p>
<p>En mi caso he incluido las siguientes lineas:</p>
<pre><code>NO_START=0
VERBOSE=yes
JETTY_PORT=8080
JETTY_HOST=0.0.0.0
JAVA_OPTIONS=&quot;-Dsolr.solr.home=/usr/share/solr $JAVA_OPTIONS&quot;
JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
</code></pre>
<ul>
<li><strong>NO_START=0</strong>: permite que Jetty se ejecute. Si el valor es 1, Jetty no podrá ejecutarse.</li>
<li><strong>VERBOSE=yes</strong>: indica a Jetty que queremos que nos muestra mucha más información durante su ejecución. Muy recomendable sobre todo cuando se intenta depurar un error.</li>
<li><strong>JETTY_PORT=8080</strong>: puerto en el que escuchará Jetty. En este caso se utiliza el puerto por defecto, pero se puede establecer cualquier otro siempre y cuand o no se encuentra ya en uso en el sistema.</li>
<li><strong>JETTY_HOST=0.0.0.0</strong>: indica a Jetty que escuche en todas las interfaces de red y no solo en localhost. Aunque es recomendable que escuche solo en localhost, sobre todo si se encuentra instalada en el mismo servidor donde se encuentra la aplicación.</li>
<li><strong>JAVA_OPTIONS</strong>: opciones y parámetros que se pueden pasar a la máquina virtual de Java.</li>
<li><strong>JAVA_HOME</strong>: indica el directorio HOME de la máquina virtual de Java. Es posible descubrirlo ejecutando <code>dpkg -L openjdk-7-jre</code>.</li>
</ul>
<h4 id="aadiendocoresasolr">Añadiendo Cores a Solr</h4>
<p>Es necesario configurar al menos un <strong>Core</strong> en Solr para que podamos hacer uso de él, así que editaremos el fichero <code>/usr/share/solr/solr.xml</code>:</p>
<pre><code>$ sudo vim /usr/share/solr/solr.xml
</code></pre>
<p>y añadiremos algo como lo siguiente:</p>
<pre><code>&lt;solr persistent=&quot;true&quot;&gt;
    &lt;cores adminPath=&quot;/admin/cores&quot;&gt;
    &lt;core name=&quot;mysitename&quot; instanceDir=&quot;mysitename&quot; dataDir=&quot;/var/lib/solr/mysitename/data&quot; /&gt;
    &lt;/cores&gt;
&lt;/solr&gt;
</code></pre>
<p>Esto añade un <strong>Core</strong> llamado <strong>mysitename</strong>. Ahora crearemos el directorio del <strong>Core</strong> que acabamos de configurar:</p>
<pre><code>$ sudo mkdir -p /var/lib/solr/mysitename/data
</code></pre>
<p>Y establecemos <strong>jetty</strong> como propietario y grupo a los directorios<br>
<code>/var/lib/solr</code> <code>/usr/share/solr</code>:</p>
<pre><code>$ sudo chown -R jetty:jetty /var/lib/solr/
$ sudo chown -R jetty:jetty /usr/share/solr
</code></pre>
<h4 id="configurandoelcore">Configurando el Core</h4>
<p>Tal y como hemos hecho antes, tenemos que crear el directorio que alojará la configuración para el Core <strong>mysitename</strong>:</p>
<pre><code>$ sudo mkdir -p /usr/share/solr/mysitename
</code></pre>
<p>Y si aún no tenemos una configuración disponible, podemos copiar la<br>
configuración de ejemplo que viene incluida con Solr y que se encuentra en el directorio <code>example</code>:</p>
<pre><code>$ sudo cp -r /opt/solr/example/solr/collection1/conf/ /usr/share/solr/mysitename/
</code></pre>
<h4 id="reiniciarjetty">Reiniciar Jetty</h4>
<p>Por último y para terminar solo nos quedaría reiniciar el servido Jetty:</p>
<pre><code>$ sudo service jetty restart
</code></pre>
<p>Si todo va bien, Solr debería estar accesible en <a href="http://localhost:8080/solr">http://localhost:8080/solr</a></p>
<p>Y esto es todo! Espero que os sirva de ayuda, a mi seguro que me va a ser muy útil cuando tenga que montar un Solr de nuevo.</p>
<p>Un saludo,<br>
Manu.</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Empezando con MongoDB Part.II]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>En mi <a href="http://manuelviera.com/blog/empezando-con-mongodb/">anterior post</a> hablaba sobre <a href="http://manuelviera.com/blog/empezando-con-mongodb/">cómo empezar con MongoDB</a>, una base de datos NoSQL orientada a documentos; y como sigo estudiándola y me parece interesante, me gustaría seguir compartiendo y profundizando sobre el uso de MongoDB, así que he decidido escribir una segunda parte de este anterior post.</p>
<p>El</p>]]></description><link>http://manuelviera.com/blog/empezando-con-mongodb-part-ii/</link><guid isPermaLink="false">5ee645fa46e19912dcb4161f</guid><category><![CDATA[tech]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Sat, 02 Mar 2013 00:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>En mi <a href="http://manuelviera.com/blog/empezando-con-mongodb/">anterior post</a> hablaba sobre <a href="http://manuelviera.com/blog/empezando-con-mongodb/">cómo empezar con MongoDB</a>, una base de datos NoSQL orientada a documentos; y como sigo estudiándola y me parece interesante, me gustaría seguir compartiendo y profundizando sobre el uso de MongoDB, así que he decidido escribir una segunda parte de este anterior post.</p>
<p>El objetivo de este post es bien sencillo. Cubrirá las operaciones principales básicas de MongoDB, también conocidas como operaciones <strong>CRUD</strong>, que significa <strong>C</strong> reate, <strong>R</strong> ead, <strong>U</strong> pdate y <strong>D</strong> elete. ¡Así que empecemos con ello!</p>
<!--more-->
<p>Antes de nada empezaremos recordando cómo iniciar nuestra base de datos<br>
utilizando el comando <code>mongod</code>. Recordad que debemos especificar la ruta donde se almacenará la base de datos utilizando el parámetro <code>--dbpath</code>. Dicho esto, podremos ejecutar una instrucción como la siguiente:</p>
<pre><code>$ mongod --dbpath test
</code></pre>
<p>En este caso he utilizado un directorio llamado <em>test</em> donde alojaré esta base de datos de pruebas. Apuntar que al no especificar un puerto con el parámetro <code>--port</code>, la instancia de <code>mongod</code> utilizará el puerto <code>27017</code> por defecto.</p>
<p>Esta instrucción tiene un &quot;inconveniente&quot; y es que no podremos seguir<br>
utilizando nuestra consola actual, pues la ejecución de <code>mongod</code> se realiza en primer plano, o <em>foreground</em>. Para evitar esto podemos hacer uso del parámetro <code>--fork</code> que creará un <em>fork</em> del proceso del servidor permitiendo poder seguir utilizando nuestra consola. La opción <code>--fork</code> requiere que se especifique además un fichero de log utilizando el parámetro <code>--logpath</code> o <code>--syslog</code>, así que la instrucción quedaría de la siguiente forma:</p>
<pre><code>$ mongod --dbpath test --logappend --logpath test.log --fork
forked process: 10017
all output going to: /home/mviera/Downloads/mongodb/test.log
child process started successfully, parent exiting
</code></pre>
<p><strong>Nota:</strong> Además he utilizado la opción <code>--logappend</code> para evitar que<br>
sobrescriba el contenido del fichero de log. En este caso seguirá concatenando datos al contenido actual del fichero.</p>
<p>Una vez funcionando nuestra instancia de <code>mongod</code>, podemos conectarnos a la<br>
consola utilizando el comando <code>mongo</code> de la siguiente forma:</p>
<pre><code>$ mongo
MongoDB shell version: 2.2.3
connecting to: test
&gt;
</code></pre>
<p><strong>Nota:</strong> No es necesario especificar el puerto porque se está utilizando  el puerto por defecto (<code>27017</code>).</p>
<p>Todo listo, así que ¡empecemos a crear documentos!</p>
<h2 id="introduciendocontenido">Introduciendo contenido</h2>
<p>Seguro que muchos ya os imagináis cómo se realiza este tipo de operación básica en una base de datos SQL como MySQL, PosgreSQL, SQLite, etc; pero en MongoDB se realiza de una forma muy diferente, por lo menos referente a cómo se realiza en una base de datos SQL.</p>
<p>Una inserción de datos sencilla en SQL podría ser de la siguiente forma:</p>
<pre><code>INSERT INTO users (firstName, lastName, username, age, city)
VALUES ('Manuel', 'Viera', 'mviera', 26, 'Sevilla');
</code></pre>
<p>En MongoDB es completamente diferente. En mi anterior post ya traté rápidamente las inserciones y si recordáis, comentaba que MongoDB está orientado a documentos y que estos documentos siguen el estilo JSON (JavaScript Object Notation).</p>
<p>Para realizar una inserción en MongoDB utilizaremos el método <code>insert()</code> al que llamaremos pasándole como parámetro el documento a introducir, el cual,<br>
siguiendo el ejemplo anterior, sería representado en formato JSON de la<br>
siguiente forma:</p>
<pre><code>{
  &quot;firstName&quot; : &quot;Manuel&quot;,
  &quot;lastName&quot; : &quot;Viera&quot;,
  &quot;username&quot; : &quot;mviera&quot;,
  &quot;age&quot; : 26,
  &quot;city&quot; : &quot;Sevilla&quot;
}
</code></pre>
<p>Recordad también que en MongoDB los documentos se almacenan en colecciones (o <em>collections</em> en inglés), así que para seguir con el ejemplo introduciremos este documento en una colección llamada <code>users</code>.</p>
<pre><code>&gt; db.users.insert({
 firstName: &quot;Manuel&quot;,
 lastName: &quot;Viera&quot;,
 username: &quot;mviera&quot;,
 age: 26,
 city: &quot;Sevilla&quot;
 })
</code></pre>
<p>Bien. ¿Qué tenemos hasta ahora? Por defecto cuando nos conectamos a una<br>
instancia MongoDB sin especificar una base de datos, se utilizará por defecto <code>test</code>. Así que hemos creado un documento dentro de la colección <code>users</code> en la base de datos <code>test</code>.</p>
<p><strong>Nota:</strong> A modo de recordatorio, no es necesario crear previamente la<br>
colección antes de introducir documentos. MongoDB lo hará por nosotros<br>
automáticamente si la colección no existe.</p>
<p>¿Pero cómo recuperamos los datos introducidos?</p>
<h2 id="recuperandolosdocumentos">Recuperando los documentos</h2>
<p>Para seleccionar, buscar, encontrar documentos dentro de nuestra colección<br>
utilizaremos uno de los siguientes métodos:</p>
<ul>
<li><code>find()</code> : que devolverá un cursor con todos los documentos recuperados de la base de datos.</li>
<li><code>findOne()</code> : que devuelve solamente un documento.</li>
</ul>
<p>El uso de <code>find()</code> es muy sencillo, como podéis ver a continuación:</p>
<pre><code>&gt; db.users.find()
{ &quot;_id&quot; : ObjectId(&quot;5131f87b350e650534c68d8e&quot;), &quot;firstName&quot; : &quot;Manuel&quot;, &quot;lastName&quot; : &quot;Viera&quot;, &quot;username&quot; : &quot;mviera&quot;, &quot;age&quot; : 26, &quot;city&quot; : &quot;Sevilla&quot; }
&gt;
</code></pre>
<p>En este caso tanto <code>find()</code> como <code>findOne()</code> devolverán resultados idénticos, pues ahora mismo sólo contamos con un documento en nuestra colección <code>users</code>:</p>
<pre><code>&gt; db.users.findOne()
{
        &quot;_id&quot; : ObjectId(&quot;5131f87b350e650534c68d8e&quot;),
        &quot;firstName&quot; : &quot;Manuel&quot;,
        &quot;lastName&quot; : &quot;Viera&quot;,
        &quot;username&quot; : &quot;mviera&quot;,
        &quot;age&quot; : 26,
        &quot;city&quot; : &quot;Sevilla&quot;
}
&gt;
</code></pre>
<p>Si os fijáis en un detalle, <code>findOne()</code> devuelve el contenido de una forma<br>
mucho más legible al ojo humano que <code>find()</code>. Esto también podemos conseguirlo con <code>find()</code> si utilizamos además el método <code>pretty()</code> de la siguiente forma:</p>
<pre><code>&gt; db.users.find().pretty()
{
        &quot;_id&quot; : ObjectId(&quot;5131f87b350e650534c68d8e&quot;),
        &quot;firstName&quot; : &quot;Manuel&quot;,
        &quot;lastName&quot; : &quot;Viera&quot;,
        &quot;username&quot; : &quot;mviera&quot;,
        &quot;age&quot; : 26,
        &quot;city&quot; : &quot;Sevilla&quot;
}
</code></pre>
<p>Al igual que <code>pretty()</code> también podemos utilizar otros métodos como <code>count()</code> que nos devuelve la cantidad total de documentos devueltos:</p>
<pre><code>&gt; db.users.find().count()
1
&gt;

O directamente sobre la colección `users` para saber el total de documentos de dicha colección:

&gt; db.users.count()
5
&gt;
</code></pre>
<p>Si introducimos más documentos de prueba, se aprecia que el contador total de documentos cambia:</p>
<pre><code>&gt; db.users.insert({firstName:&quot;Paco&quot;, lastName:&quot;Laverdaque&quot;, username: &quot;laverdaque&quot;, age: 40, city: &quot;Madrid&quot;})
&gt; db.users.insert({firstName:&quot;Raul&quot;, lastName:&quot;Martin&quot;, username: &quot;rmartin&quot;, age: 39, city: &quot;Malaga&quot;})
&gt; db.users.insert({firstName:&quot;Jose&quot;, lastName:&quot;Castillo&quot;, username: &quot;lolo&quot;, age: 25, city: &quot;Cadiz&quot;})
&gt; db.users.insert({firstName:&quot;Jose Luis&quot;, lastName:&quot;Romero&quot;, username: &quot;selu&quot;, age: 27, city: &quot;Barcelona&quot;})
&gt; 
&gt; db.users.count()
5
</code></pre>
<p>Pero no siempre vamos a querer recuperar todos los documentos de nuestra colección...</p>
<h3 id="cmofiltrardocumentos">¿Cómo filtrar documentos?</h3>
<p>Seguro que muchos ya estáis pensando en la cláusula <code>WHERE</code> de las sentencias SQL. Por ejemplo, si quisiéramos recuperar aquellos usuarios cuya ciudad es Sevilla, con una sentencia SQL sería:</p>
<pre><code>&gt; SELECT * FROM users WHERE city=&quot;Sevilla&quot;;
</code></pre>
<p>Sin embargo, en MongoDB es de la siguiente forma:</p>
<pre><code>&gt; db.users.find({ city: &quot;Sevilla&quot; })
</code></pre>
<p>De esta forma, pasamos como parámetro un documento JSON con la cláusula a<br>
cumplir, en este caso que la clave <strong>city</strong> tenga como valor <em>Sevilla</em>.</p>
<p>¿Y cómo podemos concatenar cláusulas? Es decir, cómo sería si quisiéramos<br>
recuperar aquellos usuarios cuya ciudad es Sevilla <strong>y</strong> además su edad sea 26:</p>
<pre><code>&gt; db.users.find({ city: &quot;Sevilla&quot;, age: 26 })
</code></pre>
<p>Como se puede observar, solamente se necesita agregar una segunda clave o campo al documento JSON que se le pasa al método <code>find()</code>.</p>
<p><strong>Nota:</strong> MongoDB aplica por defecto un <strong>AND</strong> entre cláusulas, es decir,<br>
imaginaos que la coma (<strong>,</strong>) es un operador <strong>AND</strong>.</p>
<p>Para utilizar un operador <strong>OR</strong> deberemos usar el operador <code>$or</code> de MongoDB, de la siguiente forma:</p>
<pre><code>&gt; db.users.find({ $or: [ {city:&quot;Sevilla&quot;}, {city:&quot;Malaga&quot;} ] })
</code></pre>
<p>En este caso hemos recuperado aquellos usuarios cuya ciudad es Sevilla <strong>o</strong> Málaga.</p>
<p>Podéis aprender más sobre operadores en <a href="http://docs.mongodb.org/manual/reference/operators/">http://docs.mongodb.org/manual/reference/operators/</a>.<br>
Algunos de ellos son:</p>
<ul>
<li><code>$gt</code>: mayor que (o <em>greater than</em> en inglés).</li>
<li>`$lt: menor que (o <em>lower than</em> en inglés).</li>
<li><code>$gte</code>: mayor o igual que (o <em>greather or equal than</em> en inglés).</li>
<li><code>$lte</code>: menor o igual que (o <em>lower or equal than</em> en inglés).</li>
<li><code>$not</code>: no (negación o <em>not</em> en inglés).</li>
<li><code>$in</code>: en, para buscar dentro de un array.</li>
<li><code>$nin</code>: no en, para buscar algo que no se encuentre en un determinado array (o <em>not in</em> en inglés).</li>
<li><code>$ne</code>: no es igual a (o <em>not equal to</em> en inglés).</li>
</ul>
<p>Pero, no siempre vamos a querer recuperar todos los campos de un documento,<br>
quizás solo necesitemos un algunos de ellos...</p>
<h2 id="cmoseleccionarciertoscampos">¿Cómo seleccionar ciertos campos?</h2>
<p>Al igual que en una sentencia <code>SELECT</code>, en una base de datos SQL, podemos<br>
especificar qué determinados campos queremos obtener tras seleccionar los<br>
documentos, en MongoDB también podemos hacerlo.</p>
<p>Hasta ahora hemos estado utilizando <code>find()</code> como una sentencia SQL <code>SELECT *</code>, es decir:</p>
<pre><code>&gt; db.users.find()
</code></pre>
<p>es equivalente a</p>
<pre><code>&gt; SELECT * FROM users;
</code></pre>
<p>Pero ¿y si lo que queremos es solamente recuperar los campos <em>username</em> y<br>
<em>age</em>? En una sentencia SQL sería de la siguiente forma:</p>
<pre><code>&gt; SELECT username, age, city FROM users;
</code></pre>
<p>En cambio, en MongoDB sería de la siguiente forma:</p>
<pre><code>&gt; db.users.find({}, {username:1, age:1})
{ &quot;_id&quot; : ObjectId(&quot;5131f87b350e650534c68d8e&quot;), &quot;username&quot; : &quot;mviera&quot;, &quot;age&quot; : 26 }
{ &quot;_id&quot; : ObjectId(&quot;5131fdc8350e650534c68d8f&quot;), &quot;username&quot; : &quot;laverdaque&quot;, &quot;age&quot; : 40 }
{ &quot;_id&quot; : ObjectId(&quot;5131fe00350e650534c68d90&quot;), &quot;username&quot; : &quot;rmartin&quot;, &quot;age&quot; : 39 }
{ &quot;_id&quot; : ObjectId(&quot;5131fe20350e650534c68d91&quot;), &quot;username&quot; : &quot;lolo&quot;, &quot;age&quot; : 25 }
{ &quot;_id&quot; : ObjectId(&quot;5131fe80350e650534c68d92&quot;), &quot;username&quot; : &quot;selu&quot;, &quot;age&quot; : 27 }
</code></pre>
<p>Sin embargo, como podéis observar, aunque no hemos especificado el campo <code>_id</code> sigue apareciendo en la salida. Como ya comenté en el anterior post, MongoDB siempre muestra el campo <code>_id</code> a menos que especifiquemos explicitamente que no queramos que lo haga. Y sería de la siguiente forma:</p>
<pre><code>&gt; db.users.find( {}, { username:1, age:1, _id:0 })
{ &quot;username&quot; : &quot;mviera&quot;, &quot;age&quot; : 26 }
{ &quot;username&quot; : &quot;laverdaque&quot;, &quot;age&quot; : 40 }
{ &quot;username&quot; : &quot;rmartin&quot;, &quot;age&quot; : 39 }
{ &quot;username&quot; : &quot;lolo&quot;, &quot;age&quot; : 25 }
{ &quot;username&quot; : &quot;selu&quot;, &quot;age&quot; : 27 }
</code></pre>
<p>En resumen, si analizamos la sintaxis del método <code>find()</code>, primero se<br>
especifica un documento JSON con las cláusulas del filtro que queremos aplicar y a continuación, si lo preferimos, podemos activar o desactivar cierto campos de la salida:</p>
<ul>
<li><strong>1</strong> : indica que queremos que muestre el campo especificado.</li>
<li><strong>0</strong> : indica que no queremos que dicho campo se muestre en la salida.</li>
</ul>
<h1 id="actualizandodatosdelosdocumentos">Actualizando datos de los documentos</h1>
<p>Una vez que somos capaces de introducir documentos en nuestra colección,<br>
recuperarlos todos o aquellos que nos interesan utilizando una <em>query</em> es hora de conocer cómo podemos actualizar los datos de nuestros documentos.</p>
<p>Para ello utilizaremos el método <code>update()</code> cuya sintaxis es la siguiente:</p>
<pre><code>&gt; db.collection.update( &lt;query&gt;, &lt;update&gt;, options )
&gt;
</code></pre>
<ul>
<li>El parámetro <code>&lt;query&gt;</code> hace referencia a una query como las que usabamos con el comando <code>find()</code>, la cual nos permitirá seleccionar aquellos documentos los cuales queremos modificar. De otra forma, si no se especifica una query se estarían seleccionando todos los documentos de una colección.</li>
<li>El parámetro <code>&lt;update&gt;</code> en el que podemos especificar un documento completo, que actualizará cada uno de los campos del documento seleccionado; o también podemos especificar solamente el campo del documento que queremos especificar, lo cual es más eficiente comparado con actualizar todos los campos del documento.</li>
</ul>
<p>Y con respecto a las opciones podemos citar:</p>
<ul>
<li><code>upsert</code>: si se establece este parámetro a <strong>true</strong> y no hay documento que coincida con la <code>&lt;query&gt;</code> especificada, el método <code>update()</code> insertará un nuevo documento en la colección con los valores especificados en el parámetro <code>&lt;update&gt;</code>.</li>
<li><code>multi</code> : por defecto MongoDB solo actualiza un documento al mismo tiempo, si necesitamos actualizar más de un documento al mismo tiempo debemos establecer este parámetro a <strong>true</strong>.</li>
</ul>
<h2 id="actualizarundocumentocompleto">Actualizar un documento completo</h2>
<p>Esta no es la forma más eficiente de actualizar el contenido de un documento, como comenté anteriormente, pues es necesario que se especifique el contenido completo del documento, y en caso de ser un documento muy grande puede llegar a ser bastante ineficiente, ya que tendra que actualizarse el valor de cada campo aunque no hay cambiado.</p>
<p>Imaginemos que queremos modificar un documento para cambiar solamente el valor del campo <strong>age</strong> (edad). Tendríamos que realizar lo siguiente:</p>
<pre><code>&gt; db.users.update({ username: &quot;rmartin&quot; }, { &quot;firstName&quot; : &quot;Raul&quot;, &quot;lastName&quot; : &quot;Martin&quot;, &quot;username&quot; : &quot;rmartin&quot;, &quot;age&quot; : 40, &quot;city&quot; : &quot;Malaga&quot; } })
</code></pre>
<p>Con esta instrucción hemos cambiado el valor del campo <strong>age</strong> de 39 a 40, incluyendo los demás campos que serán actualizados con los mismos datos.</p>
<p>También es posible hacerlo de la siguiente forma para nuestra comodidad:</p>
<pre><code>&gt; user = db.users.findOne({ username:&quot;rmartin&quot; })
{
        &quot;_id&quot; : ObjectId(&quot;5131fe00350e650534c68d90&quot;),
        &quot;firstName&quot; : &quot;Raul&quot;,
        &quot;lastName&quot; : &quot;Martin&quot;,
        &quot;username&quot; : &quot;rmartin&quot;,
        &quot;age&quot; : 39,
        &quot;city&quot; : &quot;Malaga&quot;
}
&gt; user.age 
39
&gt; 
&gt; user.age = 40
40
&gt; 
&gt; db.users.update({ username:&quot;rmartin&quot; }, user )
</code></pre>
<ol>
<li>Recupero el documento completo referente al usuario cuyo <em>username</em> es <em>rmartin</em> y lo almaceno en la variable <code>user</code>.</li>
<li>Compruebo el valor actual del campo <em>age</em> accediendo al objeto <code>user</code> haciendo uso del <em>dot notation</em> (notación por punto: user.campo)</li>
<li>Modifico el valor del campo <em>age</em> estableciéndolo a 40.</li>
<li>Utilizo el método <code>update()</code> seleccionando de nuevo el mismo objeto que al principio (usando la misma query) e indico el nuevo documento a continuación, en este caso, almacenado en la variable <code>user</code>.</li>
</ol>
<h2 id="actualizandouncampoconcretodeundocumento">Actualizando un campo concreto de un documento</h2>
<p>Sin embargo, existe una alternativa mucho más eficiente para actualizar el<br>
valor de ciertos campos en un documento. Para ello será necesario volver a<br>
hacer uso de los operadores como los anteriormente citados. Algunos de estos son:</p>
<ul>
<li>
<p><code>$set</code>: que permite establecer un nuevo valor a un campo del documento. Si el campo no existe actualmente en el documento, será creado automáticamente. Por ejemplo:</p>
<pre><code>  &gt; db.users.update({ age: 26, city: &quot;Sevilla&quot; }, { $set: { weight: 68.9 } })
</code></pre>
</li>
</ul>
<p>En este caso se ha seleccionado un usuario cuya edad sea 26 y su ciudad<br>
Sevilla, y se ha añadido el campo <strong>weight</strong>.</p>
<ul>
<li>
<p><code>$addToSet</code>: para añadir elementos un array. Por ejemplo, si quisieramos añadir un nuevo campo llamado <em>likes</em> con los gustos de un usuario:</p>
<pre><code>&gt; db.users.update({ username:&quot;mviera&quot; }, {$addToSet: { likes: &quot;photography&quot; }})
&gt; db.users.update({ username:&quot;mviera&quot; }, {$addToSet: { likes: &quot;music&quot; }})
&gt;
&gt; db.users.findOne({ username: &quot;mviera&quot; })
{
    &quot;_id&quot; : ObjectId(&quot;5131f87b350e650534c68d8e&quot;),
    &quot;age&quot; : 26,
    &quot;city&quot; : &quot;Sevilla&quot;,
    &quot;firstName&quot; : &quot;Manuel&quot;,
    &quot;lastName&quot; : &quot;Viera&quot;,
    &quot;likes&quot; : [
            &quot;photography&quot;,
            &quot;music&quot;
    ],
    &quot;username&quot; : &quot;mviera&quot;,
    &quot;weight&quot; : 68.9
}
&gt;
</code></pre>
</li>
<li>
<p><code>$inc</code>: permite incrementar el valor numérico de uno de los campos del documento. Por ejemplo, si quisieramos incrementar en 5 la edad del usuario <em>mviera</em>:</p>
<pre><code>  &gt; db.users.update({ username:&quot;mviera&quot; }, {$inc: {age: 5}})
  &gt; db.users.find({ username: &quot;mviera&quot; }, {username: 1, age: 1, _id:0})
</code></pre>
<p>{ &quot;age&quot; : 31, &quot;username&quot; : &quot;mviera&quot; }</p>
</li>
</ul>
<p>Para más información acerca de los operadores utilzados en el método <code>update()</code> podéis consultar<br>
<a href="http://docs.mongodb.org/manual/applications/update/#update-operators">http://docs.mongodb.org/manual/applications/update/#update-operators</a></p>
<h2 id="eliminandodocumentos">Eliminando documentos</h2>
<p>Para eliminar documentos de nuestra colección utilizaremos el método <code>remove()</code> en la shell de MongoDB. Si ya sabes cómo utilizar el método <code>find()</code> no supondrá ningún problema porque solamente requiere que se le especifique el filtro o búsqueda de los documentos que se quieren eliminar. Su sintaxis es la siguiente:</p>
<pre><code>db.collection.remove( &lt;query&gt;, &lt;justOne&gt; )
</code></pre>
<p>De forma que si queremos eliminar de la colección todos los usuarios cuya edad sea mayor a 30 utilizaríamos la siguiente instrucción:</p>
<pre><code>&gt; db.users.remove({ age: { $gt: 30 } })
</code></pre>
<p>El parámetro <code>justOne</code> permite indicar al método <code>remove()</code> si queremos<br>
eliminar solamente un documento de todos los coincidentes. En ese caso, se debe pasar el valor <em>true</em> o <em>1</em>, de la siguiente forma:</p>
<pre><code>&gt; db.users.remove({ age: { $gt: 30 } }, true )
</code></pre>
<p>Es posible utilizar el método <code>remove()</code> para eliminar todos los documentos de una colección si no se especifica una query o si ésta está vacía, es decir, <code>db.users.remove({})</code>. Pero en este caso, si queremos eliminar todos los documentos de una colección, es recomendable utilizar el método <code>drop()</code>, que <strong>elimina la colección completa</strong>:</p>
<pre><code>&gt; db.users.drop()
</code></pre>
<p>¡Y eso es todo! Espero que os haya sido útil y por lo menos hayáis aprendido algo nuevo. Intentaré seguir escribiendo sobre MongoDB, ahora que ya conocemos lo básico.</p>
<p>Un saludo,<br>
Manu.</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Empezando con MongoDB]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>Normalmente muchos de los que nos dedicamos a la informática, cuando escuchamos el término <em>base de datos</em> o <em>database</em> (en inglés) pensamos directamente en un tipo de base de datos, las bases de datos relacionales, como MySQL, PostgreSQL, etc; quizás porque son las más comunes y utilizadas durante mucho tiempo.</p>]]></description><link>http://manuelviera.com/blog/empezando-con-mongodb/</link><guid isPermaLink="false">5ee61de146e19912dcb415eb</guid><category><![CDATA[tech]]></category><dc:creator><![CDATA[Manuel Viera]]></dc:creator><pubDate>Wed, 06 Feb 2013 00:00:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>Normalmente muchos de los que nos dedicamos a la informática, cuando escuchamos el término <em>base de datos</em> o <em>database</em> (en inglés) pensamos directamente en un tipo de base de datos, las bases de datos relacionales, como MySQL, PostgreSQL, etc; quizás porque son las más comunes y utilizadas durante mucho tiempo. Pero esto está cambiando.</p>
<p>Desde hace un tiempo hasta ahora han ido proliferando otro tipo de base de<br>
datos conocidas como <em>NoSQL</em> y seguro que conocéis algunas como: <strong>Memcached</strong>, una caché tipo clave-valor en RAM, su variante <strong>MemcacheDB</strong> que almacena datos clave-valor en disco usando <strong>BerkeleyDB</strong>; <strong>Redis</strong>, otra base de datos de tipo clave-valor; o <strong>MongoDB</strong> que a diferencia de las anteriores, está <strong>orientada a documentos</strong>.</p>
<h2 id="quesmongodb">¿Qué es MongoDB?</h2>
<p>Primero, ¿Qué significa <em>NoSQL</em>? El término <em>NoSQL</em> se utiliza para indicar que dicha base de datos no utiliza el sistema relacional tan ampliamente utilizado. Las bases de datos <em>NoSQL</em> no se construyen sobre <em>tablas</em> y normalmente tampoco utilizan el lenguaje <em>SQL</em> para realizar consultas.</p>
<p>Muchos sistemas <em>NoSQL</em> utilizan una arquitectura distribuida y tolerante a<br>
fallos, lo que permite mantener los datos en varios servidores de forma<br>
redundante. De esta forma es bastante fácil escalar el sistema añadiendo más servidores. Normalmente este tipo de base de datos escala horizontalmente permitiendo administrar grandes cantidades de datos.</p>
<p>El nombre de <strong>MongoDB</strong> proviene de &quot;hu<strong>mongo</strong>us&quot;, que significa enorme en inglés, y es una base de datos <em>NoSQL</em> software libre, escalable y de alto rendimiento escrita en C++.</p>
<p>Algunas de las características más importantes de MongoDB son:</p>
<ol>
<li>Almacenamiento orientado a documentos (<em>document-oriented</em> en inglés).</li>
<li>Replicación y Alta Disponibilidad.</li>
<li>Soporte de índices.</li>
<li>Consultas, también basadas en documentos.</li>
<li>Auto-Sharding, permitiendo escalar horizontalmente.</li>
<li>GridFS, que permite almacenar ficheros de cualquier tamaño sin necesidad de complicar el entorno.</li>
</ol>
<h2 id="orientadoadocumentos">¿Orientado a documentos?</h2>
<p>Si hubiera que destacar una de las características anteriormente citadas, en mi opinión, la más importante ahora mismo sería la de <em>orientado a documentos</em> o <em>document-oriented</em>, ya que se trata de un concepto fundamental para entender cómo funciona y cómo trabajar con MongoDB.</p>
<p>El almacenamiento de los datos en MongoDB utiliza documentos <strong>JSON</strong><br>
(JavaScript Object Notation), contando con un esquema dinámico y totalmente<br>
flexible. De hecho se dice que MongoDB es <em>schemaless</em> (sin esquema).</p>
<h4 id="peroquesundocumentojson">¿Pero qué es un documento JSON?</h4>
<p>De forma rápida y sencilla, un documento JSON no es más que descripción de un objecto en formato JSON, un formato muy rápido para el intercambio de datos y  muy legible para el humano (<em>human-readable</em> en inglés).</p>
<p>Un documento JSON podria tener la siguiente forma:</p>
<pre><code>{&quot;username&quot;:&quot;mviera&quot;, &quot;age&quot;: 26, &quot;city&quot;: &quot;Sevilla&quot;}
</code></pre>
<p>Este documento describe un usuario cuyo &quot;<em>username</em>&quot; es &quot;mviera&quot;, con una edad de 26 años y cuya ciudad es &quot;Sevilla&quot;.</p>
<p>En JSON hay 6 tipos de datos diferentes:</p>
<ul>
<li>Number</li>
<li>String</li>
<li>Boolean (true o false)</li>
<li>Array</li>
<li>Object</li>
<li>null</li>
</ul>
<p>Podéis aprender más sobre JSON en <a href="http://json.org/json-es.html">http://json.org/json-es.html</a></p>
<h2 id="cmoseinstala">¿Cómo se instala?</h2>
<p>La instalación de MongoDB es bastante sencilla. La versión actual de MongoDB es <strong>2.2.3</strong>, en el momento en que escribo este artículo.</p>
<p>Su instalación se puede llevar a cabo a través del sistema de paquetería de<br>
nuestra distribución, APT, Aptitude, Yum... En Debian el nombre del paquete que contiene el servidor de MongoDB se llaman <strong>mongodb-server</strong> y el paquete que contiene el cliente y otras utilidades de MongoDB se llama <strong>mongodb-clients</strong>.</p>
<p>Así que si estamos en un sistema Debian o derivado, podemos instalarlo de la siguiente forma:</p>
<pre><code>mviera@mongodb:~$ sudo apt-get update
mviera@mongodb:~$ sudo apt-get install mongodb-server mongodb-clients
</code></pre>
<p>También podemos descargar los binarios desde la propia web oficial de MongoDB <a href="http://www.mongodb.org/downloads">www.mongodb.org</a> o el código fuente si lo que queremos es compilar nuestro propio MongoDB. Hay binarios disponibles para OS X, Linux, Windows para plataformas de 32 y 64bits; y Solaris 64 bits.</p>
<p>Si lo que queremos es realizar un despliegue en producción, recomendaría<br>
instalar utilizando el sistema de paquetería del sistema con el que contaremos con futuras actualizaciones de seguridad, etc. Si el objetivo es aprender MongoDB, podemos instalarlo tanto a través del sistema de paquetería, como descargando los binarios desde la web de MongoDB.</p>
<p>En este caso voy a descargar los binarios de MongoDB desde la sección de<br>
descargas de la web oficial, ya que lo utilizaré para aprender y enseñaros<br>
MongoDB. Son binarios precompilados, así que no será necesario instalar ningún paquete adicional en nuestro sistema.</p>
<p>Para ello, descargamos el tarball que se ajuste a nuestro sistema, en este<br>
caso, Linux x86-64:</p>
<pre><code>mviera@mongodb:~$ wget http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-2.2.3.tgz
mviera@mongodb:~$ tar xzf mongodb-linux-x86_64-2.2.3.tgz                                         
mviera@mongodb:~$ ln -s mongodb-linux-x86_64-2.2.3 mongodb                   
mviera@mongodb:~$ cd mongodb
mviera@mongodb:~/mongodb$ 
</code></pre>
<p><strong>Nota:</strong> he creado un enlace simbólico llamado <em>mongodb</em> para evitar tener<br>
acceder a un directorio con un nombre tan largo y complejo.</p>
<p>Si listamos el contenido del directorio recién descomprimido, deberíamos tener algo similar a los siguiente:</p>
<pre><code>mviera@mongodb:~/mongodb$ tree 
.
|-- GNU-AGPL-3.0
|-- README
|-- THIRD-PARTY-NOTICES
`-- bin
    |-- bsondump
    |-- mongo
    |-- mongod
    |-- mongodump
    |-- mongoexport
    |-- mongofiles
    |-- mongoimport
    |-- mongooplog
    |-- mongoperf
    |-- mongorestore
    |-- mongos
    |-- mongosniff
    |-- mongostat
    `-- mongotop

1 directory, 17 files
</code></pre>
<p>Entre ellos se encuentran el fichero de licencia <em>GNU-AGPL-3.0</em>, el<br>
fichero_README_ y <em>THIRD-PARTY-NOTICES</em>; y el directorio <em>bin/</em> que contiene todos los binarios y utilidades necesarios para empezar con MongoDB. Aunque hay una buena selección de utilidades, de momento sólo vamos a utilizar <strong>mongod</strong> y <strong>mongo</strong> para familiarizarnos con MongoDB.</p>
<p>Si la instalación de MongoDB se ha realizado utilizando el sistema de<br>
paquetería del sistema, estas utilidades y herramientas se encontrarán en los directorios habituales como <em>/usr/bin</em>. En caso de Debian, es posible consultar los ficheros instalados con la siguiente instrucción:</p>
<pre><code>mviera@mongodb:~$ dpkg -L mongodb-server mongodb-clients
</code></pre>
<h2 id="primeratomadecontacto">Primera toma de contacto</h2>
<p>Una vez tenemos MongoDB instalado en nuestro sistema, lo primero que debemos hacer es iniciar la base de datos. Para ello utilizaremos <em>mongod</em>. Si se ha instalado utilizando paquetería, es posible que se haya iniciado la base de datos automáticamente, especialmente en distribuciones basadas en Debian.</p>
<p>Antes de ejecutarlo se necesita especificar el directorio donde se alojará la base de datos. Por defecto, MongoDB buscará el directorio <em>/data/db</em> y si no lo encuentra, se producirá un error como el siguiente:</p>
<pre><code>*********************************************************************
 ERROR: dbpath (/data/db/) does not exist.
 Create this directory or give existing directory in --dbpath.
 See http://dochub.mongodb.org/core/startingandstoppingmongo
*********************************************************************
</code></pre>
<p>Así que para evitar dicho error, crearemos un directorio local llamado <em>data</em> en la ruta actual y especificaremos dicho directorio con el parámetro <em>--dbpath</em> de la siguiente forma:</p>
<pre><code>mviera@mongodb:~/mongodb$ mkdir data 
mviera@mongodb:~/mongodb$ ./bin/mongod --dbpath data
</code></pre>
<p>Si todo ha ido bien, deberíamos ver algo similar a la siguiente salida:</p>
<pre><code>mviera@mongodb:~/mongodb$ ./bin/mongod --dbpath data/
Wed Feb  6 01:36:44 [initandlisten] MongoDB starting : pid=1082 port=27017 dbpath=data/ 64-bit host=mongodb
Wed Feb  6 01:36:44 [initandlisten] db version v2.2.3, pdfile version 4.5
Wed Feb  6 01:36:44 [initandlisten] git version: f570771a5d8a3846eb7586eaffcf4c2f4a96bf08
Wed Feb  6 01:36:44 [initandlisten] build info: Linux ip-10-2-29-40 2.6.21.7-2.ec2.v1.2.fc8xen ...
Wed Feb  6 01:36:44 [initandlisten] options: { dbpath: &quot;data/&quot; }
Wed Feb  6 01:36:44 [initandlisten] journal dir=data/journal
Wed Feb  6 01:36:44 [initandlisten] recover : no journal files present, no recovery needed
Wed Feb  6 01:36:44 [websvr] admin web console waiting for connections on port 28017
Wed Feb  6 01:36:44 [initandlisten] waiting for connections on port 27017
</code></pre>
<p>Como se puede observar, MongoDB se encuentra funcionando en el puerto <strong>27017</strong> por defecto, su directorio de almacenamiento de la base de datos se encuentra en <strong>dbpath=data/</strong> y además ofrece una consola de administración en el puerto <strong>28017</strong>, a través de la cual podemos visualizar el log, listar bases de datos, etc.</p>
<p>Si echamos un vistazo al directorio <em>data/</em> deberíamos ver algo similar a lo siguiente:</p>
<pre><code>mviera@mongodb:~/mongodb$ ls -l data/
total 8
drwxrwxr-x 2 mviera mviera 4096 Feb  6 01:36 journal
-rwxrwxr-x 1 mviera mviera    5 Feb  6 01:36 mongod.lock
</code></pre>
<p>Actualmente, sólo tendremos un directorio <em>journal/</em> para recuperaciones de<br>
datos en caso de desastre y el fichero <em>mongod.lock</em> que almacena el PID del proceso <em>mongod</em>.</p>
<h2 id="interactuandoconmongodb">Interactuando con MongoDB</h2>
<p>Una vez tenemos nuestra base de datos MongoDB iniciada, el siguiente paso será conectar a ella utilizando la consola o <em>shell</em>, en inglés, de Mongo. Para ello utilizaremos <em>mongo</em> ejecutando la siguiente instrucción:</p>
<pre><code>mviera@mongodb:~/mongodb$ ./bin/mongo
MongoDB shell version: 2.2.3
connecting to: test
Welcome to the MongoDB shell.
For interactive help, type &quot;help&quot;.
For more comprehensive documentation, see
    http://docs.mongodb.org/
Questions? Try the support group
    http://groups.google.com/group/mongodb-user
&gt; 
</code></pre>
<p>Si todo va bien, espero que sí, deberíamos ver el prompt de MongoDB. Por<br>
defecto Mongo, si no se le especifica lo contrario, siempre conectará a una<br>
base de datos <strong>test</strong> en la que podremos realizar todas las pruebas que<br>
queramos.</p>
<p>La <em>shell</em> de Mongo es una shell interactiva de JavaScript, por lo que podremos hacer uso de código JavaScript en caso de que nos sea necesario. Es decir, podemos realizar operaciones básicas de JavaScript como las siguientes en la shell de Mongo:</p>
<pre><code>&gt; 2 + 3
5
&gt; 
&gt; 10 * 2
20
&gt; 
&gt; var double = function (n1) { return n1 * n1 }
&gt; double(2)
4
&gt; double
function (n1) {
    return n1 * n1;
}
&gt; stuff = [1, 2, 3, 4]
[ 1, 2, 3, 4 ]
&gt; for (n in stuff) { print( parseInt(n) * 2 ) }
0
2
4
6
&gt; var x = {name: &quot;mviera&quot;, age: 26}
&gt; x.age
26
&gt; x.city = &quot;Sevilla&quot;
Sevilla
&gt; x
{ &quot;name&quot; : &quot;mviera&quot;, &quot;age&quot; : 26, &quot;city&quot; : &quot;Sevilla&quot; }
</code></pre>
<p><strong>IMPORTANTE:</strong> Estas instrucciones <strong>NO</strong> son de MongoDB, es puro JavaScript. <strong>La consola de MongoDB es una shell interactiva de JavaScript</strong>.</p>
<h2 id="familiarizacinconelentorno">Familiarización con el entorno...</h2>
<p>Bien. Estamos conectados a la consola de Mongo, así que nuestro siguiente paso será crear una base de datos. Podemos comprobar cuál es la base de datos que estamos usando actualmente llamando al objeto <strong>db</strong>:</p>
<pre><code>&gt; db
test
&gt; 
</code></pre>
<p>Crear una base de datos es tan fácil como ejecutar lo siguiente:</p>
<pre><code>&gt; use mydb
switched to db mydb
&gt; db
mydb
&gt; 
</code></pre>
<p>Podemos observar que el valor del objeto <em>db</em> ha cambiado a <strong>mydb</strong>. Lo<br>
siguiente será crear una colección, llamado <em>collection</em> en inglés. Las<br>
colecciones son los contenedores de los documentos en MongoDB. Serían las<br>
conocidas tablas que contienen los datos en las bases de datos relacionales.</p>
<p>Podemos crear una colección de prueba de la siguiente forma:</p>
<pre><code>&gt; db.createCollection(&quot;test&quot;)
{ &quot;ok&quot; : 1 }
&gt; 
&gt; show collections
system.indexes
test
</code></pre>
<p>Pero en MongoDB no es necesario crear una colección antes de introducir datos por primera vez, ya que Mongo comprobará previamente si existe la colección y si no, la creará automáticamente por nosotros.</p>
<pre><code>&gt; db.test2.insert({username:&quot;mviera&quot;})
&gt; 
&gt; show collections
system.indexes
test
test2
</code></pre>
<p>Como se puede observar, la colección <strong>test2</strong> se ha creado automáticamente al crear el documento <code>{username:&quot;mviera&quot;}</code> dentro de él. Con esto ya he<br>
introducido rápidamente la forma de introducir datos en una colección de<br>
MongoDB. De todas formas, la sintaxis de uso es la siguiente:</p>
<pre><code>db.&lt;nombre_coleccion&gt;.verbo()
</code></pre>
<p>Donde <code>verbo()</code> puede ser:</p>
<ul>
<li><code>insert</code>: para insertar documentos en la colección.</li>
<li><code>find</code>: para buscar o seleccionar documentos dentro de la colección.</li>
<li><code>count</code>: para contar el total de documentos dentro de una colección.</li>
<li><code>update</code>: para actualizar uno o varios documentos dentro de una colección.</li>
<li><code>remove</code>: para eliminar documentos de la colección.</li>
<li><code>drop</code>: para eliminar una colección.</li>
</ul>
<h2 id="hagamosunosejercicios">Hagamos unos ejercicios</h2>
<p>Nuestra base de datos actual se llama <code>mydb</code>:</p>
<pre><code>&gt; db
mydb
&gt; 
</code></pre>
<p>y actualmente nuestra base de datos sólo contiene tres colecciones:<br>
<code>system.indexes</code> (creada por MongoDB automáticamente), <code>test</code> y <code>test2</code>:</p>
<pre><code>&gt; show collections
system.indexes
test
test2
&gt; 
</code></pre>
<p>Crearemos tres documentos que describirán usuarios dentro de una colección que se llamará <code>users</code>. Los datos a almacenar en los documentos serán: username, age (edad), y ciudad. Para ello utilizaremos el método <code>insert</code> y podemos hacerlo de varias formas:</p>
<ol>
<li>
<p>Directamente especificando el documento JSON en el método <code>insert()</code>:</p>
<blockquote>
<p>db.users.insert({username:&quot;mviera&quot;,age:26,city:&quot;Sevilla&quot;})<br>
db.users.insert({username:&quot;robot&quot;, age:32, city:&quot;Cadiz&quot;})<br>
db.users.insert({username:&quot;testuser&quot;, age:20, city:&quot;Malaga&quot;})</p>
</blockquote>
</li>
<li>
<p>Almacenar los documentos en variables JavaScript y posteriormente utilizar dicha variable en <code>insert()</code>:</p>
<pre><code>   &gt; user1 = {username:&quot;mviera&quot;,age:26,city:&quot;Sevilla&quot;}
   { &quot;username&quot; : &quot;mviera&quot;, &quot;age&quot; : 26, &quot;city&quot; : &quot;Sevilla&quot; }
   &gt; user2 = {username:&quot;robot&quot;, age:32, city:&quot;Cadiz&quot;}
   { &quot;username&quot; : &quot;robot&quot;, &quot;age&quot; : 32, &quot;city&quot; : &quot;Cadiz&quot; }
   &gt; user3 = {username:&quot;testuser&quot;, age:20, city:&quot;Malaga&quot;}
   { &quot;username&quot; : &quot;testuser&quot;, &quot;age&quot; : 20, &quot;city&quot; : &quot;Malaga&quot; }
   &gt; 
   &gt; 
   &gt; db.users.insert(user1)
   &gt; db.users.insert(user2)
   &gt; db.users.insert(user3)
</code></pre>
</li>
<li>
<p>Utilizando un for loop de JavaScript en la shell de Mongo para automatizar la tarea:</p>
<pre><code>   &gt; users = [user1, user2, user3]
   &gt; for (i = 0; i &lt; users.length; i++) { db.users.insert(users[i]) }
</code></pre>
</li>
</ol>
<p><strong>Nota:</strong> Realmente en los tres casos hemos hecho lo mismo, pero solamente<br>
quería mostrar la potencia que ofrece la shell de Mongo, una shell de<br>
JavaScript.</p>
<p>Si consultamos de nuevo las colecciones disponibles en nuestra base de datos <code>mydb</code>, podremos observar que MongoDB ha creado la colección <code>users</code> por nosotros, y de forma automática:</p>
<pre><code>&gt; show collections
system.indexes
test
test2
users
&gt; 
</code></pre>
<p>Después de esto, deberíamos ser capaces de saber cuántos documentos hay en lacolección <code>users</code>, pero podemos cerciorarnos utilizando el método <code>count</code> en nuestra colección:</p>
<pre><code>&gt; db.users.count()
3
&gt; 
</code></pre>
<p>¡Perfecto! Eso quiere decir que hasta ahora ha ido todo de maravilla. Ya solo nos falta poder seleccionar dichos documentos, es decir, poder recuperar dicha información de la base de datos. Esto lo conseguiremos con el método <code>find</code>, ejecutando lo siguiente:</p>
<pre><code>&gt; db.users.find()
{ &quot;_id&quot; : ObjectId(&quot;51118e261caf692fdfc89517&quot;), &quot;username&quot; : &quot;mviera&quot;, &quot;age&quot; : 26, &quot;city&quot; : &quot;Sevilla&quot; }
{ &quot;_id&quot; : ObjectId(&quot;51118e261caf692fdfc89518&quot;), &quot;username&quot; : &quot;robot&quot;, &quot;age&quot; : 32, &quot;city&quot; : &quot;Cadiz&quot; }
{ &quot;_id&quot; : ObjectId(&quot;51118e261caf692fdfc89519&quot;), &quot;username&quot; : &quot;testuser&quot;, &quot;age&quot; : 20, &quot;city&quot; : &quot;Malaga&quot; }
&gt; 
</code></pre>
<p>¡Bien! Pero... seguro que os estáis preguntando por ese campo llamado <code>_id</code>... ¿Qué significa?¿Por qué está ahí?</p>
<p>En MongoDB todo documento tiene que tener un <strong>identificador único dentro de la colección</strong> que puede ser especificado explicitamente con el campo <code>_id</code> dentro del documento, y si no se especifica ninguno, Mongo creará uno automáticamente por nosotros sin que tengamos que preocuparnos de ello.</p>
<p>De esta forma, podemos introducir un nuevo documento que sí tenga especificado un <code>_id</code> por nosotros:</p>
<pre><code>&gt; db.users.insert({_id: 101, username:&quot;iloveyou&quot;, age: 12, likes: &quot;destroy your computer&quot;})
&gt;
</code></pre>
<p>Y si ahora volvemos a recuperar todos los documentos de la colección <code>users</code>, debería aparecer el nuevo documento en la lista:</p>
<pre><code>&gt; db.users.find()
{ &quot;_id&quot; : ObjectId(&quot;51118e261caf692fdfc89517&quot;), &quot;username&quot; : &quot;mviera&quot;, &quot;age&quot; : 26, &quot;city&quot; : &quot;Sevilla&quot; }
{ &quot;_id&quot; : ObjectId(&quot;51118e261caf692fdfc89518&quot;), &quot;username&quot; : &quot;robot&quot;, &quot;age&quot; : 32, &quot;city&quot; : &quot;Cadiz&quot; }
{ &quot;_id&quot; : ObjectId(&quot;51118e261caf692fdfc89519&quot;), &quot;username&quot; : &quot;testuser&quot;, &quot;age&quot; : 20, &quot;city&quot; : &quot;Malaga&quot; }
{ &quot;_id&quot; : 101, &quot;username&quot; : &quot;iloveyou&quot;, &quot;age&quot; : 12, &quot;likes&quot; : &quot;destroy your computer&quot; }
&gt;
</code></pre>
<p>¿Recordáis lo que comentaba al principio sobre <em>schemaless</em>? Si se observa ellistado de documentos anterior, se puede ver que los campos de los tres<br>
primeros documentos son <em>username</em>, <em>age</em> y <em>city</em>. Pero sin embargo, el nuevo documento introducido no solo no utiliza el campo <em>city</em> sino que además incluye uno nuevo llamado <em>likes</em>.</p>
<p>Esto es debido a la flexibilidad que ofrece MongoDB en sus esquemas, es decir, no todos los documentos tienen que tener los mismo campos, sino que pueden incluirse o no ciertos campos según convenga. De hecho, podría haberse incluido el campo <code>city</code> con un valor <code>null</code> pero si no lo incluimos, en el futuro ahorraremos espacio en la base de datos.</p>
<h2 id="retrospectiva">Retrospectiva</h2>
<p>Después de todo esto, algo habrá ocurrido en nuestro directorio <em>data/</em> donde se alojan las bases de datos. Si listamos el contenido del directorio, deberíamos ver algo como lo siguiente:</p>
<pre><code>mviera@mongodb:~/mongodb$ ls -lh data/
total 209M
drwxrwxr-x 2 mviera mviera 4.0K Feb  6 02:40 _tmp
drwxrwxr-x 2 mviera mviera 4.0K Feb  6 03:22 journal
-rwxrwxr-x 1 mviera mviera    0 Feb  6 03:22 mongod.lock
-rw------- 1 mviera mviera  64M Feb  6 03:08 mydb.0
-rw------- 1 mviera mviera 128M Feb  6 02:12 mydb.1
-rw------- 1 mviera mviera  16M Feb  6 03:08 mydb.ns
</code></pre>
<p>Podemos observar que se han creado dos ficheros <code>mydb.0</code> y <code>mydb.1</code> que<br>
contienen los datos; y otro fichero llamado <code>mydb.ns</code> que contiene el<br>
namespace. Si no estoy equivocado, y si lo estoy, por favor corregidme, MongoDB creará nuevos ficheros cuando los actuales ocupen un tamaño de 2G, con el fin de facilitar el traslado de estos fichero a través de la red, etc.</p>
<h2 id="apagayvmonos">Apaga y vámonos</h2>
<p>Por último y para terminar el post, os comentaré cómo podemos para el servidor Mongo de forma correcta. Es muy sencillo, solamente tenemos que cambiar a la base de datos llamada <code>admin</code>:</p>
<pre><code>&gt; use admin
switched to db admin
&gt; db
admin
&gt; 
</code></pre>
<p>y ejecutar el método <code>shutdownServer</code> de la siguiente forma:</p>
<pre><code>&gt; db.shutdownServer()
Wed Feb  6 03:29:30 DBClientCursor::init call() failed
Wed Feb  6 03:29:30 query failed : admin.$cmd { shutdown: 1.0 } to: 127.0.0.1:27017
server should be down...
</code></pre>
<p>¡Y esto es todo por ahora! Espero que el post haya sido de vuestro agrado y<br>
agradeceros a aquellos que hayáis llegado leyendo hasta esta linea. ¡Gracias!</p>
<p>Con respecto a MongoDB es tipo de base de datos nueva para mi y que me está<br>
gustando bastante. Estoy estudiándola y aprendiendo a través de un curso de<br>
10gen, la empresa que la desarrolla. El curso es totalmente gratuito, no se si es posible apuntarse a estas alturas, ya que lleva tres semanas, pero os<br>
recomiendo que lo tengáis en cuenta para próximas ediciones. Podeis encontrarlo en <a href="https://education.10gen.com">https://education.10gen.com</a></p>
<p>¡No olvideis comentar vuestras dudas o sugerencias!</p>
<p>Un saludo, Manu.</p>
<!--kg-card-end: markdown-->]]></content:encoded></item></channel></rss>