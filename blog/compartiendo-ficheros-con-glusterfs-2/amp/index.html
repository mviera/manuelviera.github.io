<!DOCTYPE html>
<html ⚡>
<head>
    <meta charset="utf-8">

    <title>Compartiendo ficheros con GlusterFS</title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <link rel="shortcut icon" href="../../../favicon.ico" type="image/x-icon" />
    <link rel="canonical" href="../index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="Manuel Viera" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Compartiendo ficheros con GlusterFS" />
    <meta property="og:description" content="Cuando aparece la necesidad de escalar una aplicación web, o cualquier otro servicio, en Internet; también aparecen nuevos problemas a resolver que antes incluso ni habíamos reparado en ellos. Uno de estos problemas es la compartición de ficheros entre servidores.  En mi opinión, a día de hoy éste sigue siendo" />
    <meta property="og:url" content="http://manuelviera.com/blog/compartiendo-ficheros-con-glusterfs-2/" />
    <meta property="og:image" content="https://images.unsplash.com/photo-1569235186275-626cb53b83ce?ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;fm&#x3D;jpg&amp;crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;w&#x3D;2000&amp;fit&#x3D;max&amp;ixid&#x3D;eyJhcHBfaWQiOjExNzczfQ" />
    <meta property="article:published_time" content="2016-08-02T00:00:00.000Z" />
    <meta property="article:modified_time" content="2020-09-13T17:14:58.000Z" />
    <meta property="article:tag" content="tech" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Compartiendo ficheros con GlusterFS" />
    <meta name="twitter:description" content="Cuando aparece la necesidad de escalar una aplicación web, o cualquier otro servicio, en Internet; también aparecen nuevos problemas a resolver que antes incluso ni habíamos reparado en ellos. Uno de estos problemas es la compartición de ficheros entre servidores.  En mi opinión, a día de hoy éste sigue siendo" />
    <meta name="twitter:url" content="http://manuelviera.com/blog/compartiendo-ficheros-con-glusterfs-2/" />
    <meta name="twitter:image" content="https://images.unsplash.com/photo-1569235186275-626cb53b83ce?ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;fm&#x3D;jpg&amp;crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;w&#x3D;2000&amp;fit&#x3D;max&amp;ixid&#x3D;eyJhcHBfaWQiOjExNzczfQ" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Manuel Viera" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="tech" />
    <meta name="twitter:site" content="@mviera" />
    <meta name="twitter:creator" content="@mviera" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="1331" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Manuel Viera",
        "url": "http://manuelviera.com/",
        "logo": {
            "@type": "ImageObject",
            "url": "http://manuelviera.com/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "Manuel Viera",
        "image": {
            "@type": "ImageObject",
            "url": "http://manuelviera.com/content/images/2020/06/2020-06-22-161222_428x430_scrot.png",
            "width": 428,
            "height": 430
        },
        "url": "http://manuelviera.com/author/mviera/",
        "sameAs": [
            "https://manuelviera.com",
            "https://twitter.com/mviera"
        ]
    },
    "headline": "Compartiendo ficheros con GlusterFS",
    "url": "http://manuelviera.com/blog/compartiendo-ficheros-con-glusterfs-2/",
    "datePublished": "2016-08-02T00:00:00.000Z",
    "dateModified": "2020-09-13T17:14:58.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://images.unsplash.com/photo-1569235186275-626cb53b83ce?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ",
        "width": 2000,
        "height": 1331
    },
    "keywords": "tech",
    "description": "Cuando aparece la necesidad de escalar una aplicación web, o cualquier otro\nservicio, en Internet; también aparecen nuevos problemas a resolver que antes\nincluso ni habíamos reparado en ellos. Uno de estos problemas es la compartición\nde ficheros entre servidores.\n\nEn mi opinión, a día de hoy éste sigue siendo un dolor de cabeza para muchos\nSysadmins o Systems Architects. Hay muchas formas de compartir ficheros entre\nservidores como NFS, S3FS, FileConveyor, un crontab con un rsync entre\nservidor",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://manuelviera.com/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.19" />
    <link rel="alternate" type="application/rss+xml" title="Manuel Viera" href="../../rss/index.html" />

    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,600,400" />
    <style amp-custom>html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:bold}dfn{font-style:italic}h1{margin:0.67em 0;font-size:2em}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{position:relative;vertical-align:baseline;font-size:75%;line-height:0}sup{top:-0.5em}sub{bottom:-0.25em}img{border:0}amp-img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}button,input,optgroup,select,textarea{margin:0;color:inherit;font:inherit}button{overflow:visible}button,select{text-transform:none}button,html input[type="button"],input[type="reset"],input[type="submit"]{cursor:pointer;-webkit-appearance:button}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}input{line-height:normal}input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}input[type="number"]::-webkit-inner-spin-button,input[type="number"]::-webkit-outer-spin-button{height:auto}input[type="search"]{-webkit-appearance:textfield}input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}fieldset{margin:0 2px;padding:0.35em 0.625em 0.75em;border:1px solid #c0c0c0}legend{padding:0;border:0}textarea{overflow:auto}optgroup{font-weight:bold}table{border-spacing:0;border-collapse:collapse}td,th{padding:0}html{max-height:100%;height:100%;font-size:62.5%;-webkit-tap-highlight-color:rgba(0,0,0,0)}body{max-height:100%;height:100%;color:#3a4145;background:#f4f8fb;letter-spacing:0.01rem;font-family:"Merriweather",serif;font-size:1.8rem;line-height:1.75em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"kern" 1;-moz-font-feature-settings:"kern" 1;-o-font-feature-settings:"kern" 1}::-moz-selection{background:#d6edff}::selection{background:#d6edff}h1,h2,h3,h4,h5,h6{margin:0 0 0.3em 0;color:#2e2e2e;font-family:"Open Sans",sans-serif;line-height:1.15em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"dlig" 1,"liga" 1,"lnum" 1,"kern" 1;-moz-font-feature-settings:"dlig" 1,"liga" 1,"lnum" 1,"kern" 1;-o-font-feature-settings:"dlig" 1,"liga" 1,"lnum" 1,"kern" 1}h1{text-indent:-2px;letter-spacing:-1px;font-size:2.6rem}h2{letter-spacing:0;font-size:2.4rem}h3{letter-spacing:-0.6px;font-size:2.1rem}h4{font-size:1.9rem}h5{font-size:1.8rem}h6{font-size:1.8rem}a{color:#4a4a4a}a:hover{color:#111}p,ul,ol,dl{margin:0 0 2.5rem 0;font-size:1.5rem;text-rendering:geometricPrecision;-webkit-font-feature-settings:"liga" 1,"onum" 1,"kern" 1;-moz-font-feature-settings:"liga" 1,"onum" 1,"kern" 1;-o-font-feature-settings:"liga" 1,"onum" 1,"kern" 1}ol,ul{padding-left:2em}ol ol,ul ul,ul ol,ol ul{margin:0 0 0.4em 0;padding-left:2em}dl dt{float:left;clear:left;overflow:hidden;margin-bottom:1em;width:180px;text-align:right;text-overflow:ellipsis;white-space:nowrap;font-weight:700}dl dd{margin-bottom:1em;margin-left:200px}li{margin:0.4em 0}li li{margin:0}hr{display:block;margin:1.75em 0;padding:0;height:1px;border:0;border-top:#efefef 1px solid}blockquote{box-sizing:border-box;margin:1.75em 0 1.75em 0;padding:0 0 0 1.75em;border-left:#4a4a4a 0.4em solid;-moz-box-sizing:border-box}blockquote p{margin:0.8em 0;font-style:italic}blockquote small{display:inline-block;margin:0.8em 0 0.8em 1.5em;color:#ccc;font-size:0.9em}blockquote small:before{content:"\2014 \00A0"}blockquote cite{font-weight:700}blockquote cite a{font-weight:normal}mark{background-color:#fdffb6}code,tt{padding:1px 3px;border:#e3edf3 1px solid;background:#f7fafb;border-radius:2px;white-space:pre-wrap;font-family:Inconsolata,monospace,sans-serif;font-size:0.85em;font-feature-settings:"liga" 0;-webkit-font-feature-settings:"liga" 0;-moz-font-feature-settings:"liga" 0}pre{overflow:auto;box-sizing:border-box;margin:0 0 1.75em 0;padding:10px;width:100%;border:#e3edf3 1px solid;background:#f7fafb;border-radius:3px;white-space:pre;font-family:Inconsolata,monospace,sans-serif;font-size:0.9em;-moz-box-sizing:border-box}pre code,pre tt{padding:0;border:none;background:transparent;white-space:pre-wrap;font-size:inherit}kbd{display:inline-block;margin-bottom:0.4em;padding:1px 8px;border:#ccc 1px solid;background:#f4f4f4;border-radius:4px;box-shadow:0 1px 0 rgba(0,0,0,0.2),0 1px 0 0 #fff inset;color:#666;text-shadow:#fff 0 1px 0;font-size:0.9em;font-weight:700}table{box-sizing:border-box;margin:1.75em 0;max-width:100%;width:100%;background-color:transparent;-moz-box-sizing:border-box}table th,table td{padding:8px;border-top:#efefef 1px solid;vertical-align:top;text-align:left;line-height:20px}table th{color:#000}table caption + thead tr:first-child th,table caption + thead tr:first-child td,table colgroup + thead tr:first-child th,table colgroup + thead tr:first-child td,table thead:first-child tr:first-child th,table thead:first-child tr:first-child td{border-top:0}table tbody + tbody{border-top:#efefef 2px solid}table table table{background-color:#fff}table tbody > tr:nth-child(odd) > td,table tbody > tr:nth-child(odd) > th{background-color:#f6f6f6}table.plain tbody > tr:nth-child(odd) > td,table.plain tbody > tr:nth-child(odd) > th{background:transparent}iframe,amp-iframe,.fluid-width-video-wrapper{display:block;margin:1.75em 0}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper amp-iframe{margin:0}textarea,select,input{margin:0 0 5px 0;padding:6px 9px;width:260px;outline:0;border:#e7eef2 1px solid;background:#fff;border-radius:4px;box-shadow:none;font-family:"Open Sans",sans-serif;font-size:1.6rem;line-height:1.4em;font-weight:100;-webkit-appearance:none}textarea{min-width:250px;min-height:80px;max-width:340px;width:100%;height:auto}input[type="text"]:focus,input[type="email"]:focus,input[type="search"]:focus,input[type="tel"]:focus,input[type="url"]:focus,input[type="password"]:focus,input[type="number"]:focus,input[type="date"]:focus,input[type="month"]:focus,input[type="week"]:focus,input[type="time"]:focus,input[type="datetime"]:focus,input[type="datetime-local"]:focus,textarea:focus{outline:none;outline-width:0;border:#bbc7cc 1px solid;background:#fff}select{width:270px;height:30px;line-height:30px}.clearfix:before,.clearfix:after{content:" ";display:table}.clearfix:after{clear:both}.clearfix{zoom:1}.main-header{position:relative;display:table;overflow:hidden;box-sizing:border-box;width:100%;height:50px;background:#5ba4e5 no-repeat center center;background-size:cover;text-align:left;-webkit-box-sizing:border-box;-moz-box-sizing:border-box}.content{background:#fff;padding-top:15px}.blog-title,.content{margin:auto;max-width:600px}.blog-title a{display:block;padding-right:16px;padding-left:16px;height:50px;color:#fff;text-decoration:none;font-family:"Open Sans",sans-serif;font-size:16px;line-height:50px;font-weight:600}.post{position:relative;margin-top:0;margin-right:16px;margin-left:16px;padding-bottom:0;max-width:100%;border-bottom:#ebf2f6 1px solid;word-wrap:break-word;font-size:0.95em;line-height:1.65em}.post-header{margin-bottom:1rem}.post-title{margin-bottom:0}.post-title a{text-decoration:none}.post-meta{display:block;margin:3px 0 0 0;color:#9eabb3;font-family:"Open Sans",sans-serif;font-size:1.3rem;line-height:2.2rem}.post-meta a{color:#9eabb3;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-meta .author{margin:0;font-size:1.3rem;line-height:1.3em}.post-date{display:inline-block;text-transform:uppercase;white-space:nowrap;font-size:1.2rem;line-height:1.2em}.post-image{margin:0;padding-top:3rem;padding-bottom:30px;border-top:1px #E8E8E8 solid}.post-image img{object-fit:cover;}.post-content amp-img,.post-content amp-anim{position:relative;left:50%;display:block;padding:0;min-width:0;max-width:112%;width:calc(100% + 32px);height:auto;transform:translateX(-50%);-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%)}.footnotes{font-size:1.3rem;line-height:1.6em;font-style:italic}.footnotes li{margin:0.6rem 0}.footnotes p{margin:0}.footnotes p a:last-child{text-decoration:none}.site-footer{position:relative;margin:0 auto 20px auto;padding:1rem 15px;max-width:600px;color:rgba(0,0,0,0.5);font-family:"Open Sans",sans-serif;font-size:1.1rem;line-height:1.75em}.site-footer a{color:rgba(0,0,0,0.5);text-decoration:none;font-weight:bold}.site-footer a:hover{border-bottom:#bbc7cc 1px solid}.poweredby{display:block;float:right;width:45%;text-align:right}.copyright{display:block;float:left;width:45%}</style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    

</head>

<body class="amp-template">
    <header class="main-header">
        <nav class="blog-title">
            <a href="../../../index.html">Manuel Viera</a>
        </nav>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Compartiendo ficheros con GlusterFS</h1>
                <section class="post-meta">
                    <p class="author">by <a href="../../../author/mviera/index.html">Manuel Viera</a></p>
                    <time class="post-date" datetime="2016-08-02">2016-08-02</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="https://images.unsplash.com/photo-1569235186275-626cb53b83ce?ixlib&#x3D;rb-1.2.1&amp;q&#x3D;80&amp;fm&#x3D;jpg&amp;crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;w&#x3D;2000&amp;fit&#x3D;max&amp;ixid&#x3D;eyJhcHBfaWQiOjExNzczfQ" width="600" height="400" layout="responsive"></amp-img>
            </figure>
            <section class="post-content">

                <p>Cuando aparece la necesidad de escalar una aplicación web, o cualquier otro servicio, en Internet; también aparecen nuevos problemas a resolver que antes incluso ni habíamos reparado en ellos. Uno de estos problemas es <strong>la compartición de ficheros</strong> entre servidores.</p>
<p>En mi opinión, a día de hoy éste sigue siendo un dolor de cabeza para muchos Sysadmins o Systems Architects. Hay muchas formas de compartir ficheros entre servidores como NFS, S3FS, FileConveyor, un crontab con un rsync entre servidores. Hay muchas soluciones, algunas mejores y otras peores; pero hoy quería compartir la que hasta ahora creo que puede ser una buena solución para compartir ficheros, usando <strong>GlusterFS</strong>.</p>
<p><a href="https://www.glusterfs.org">GlusterFS</a> es un sistema de ficheros escalable en red, con el que poder crear soluciones de almacenamiento distribuidos por la red y de gran capacidad. Ni que decir tiene que <strong>GlusterFS</strong> es software libre.</p>
<h2 id="antesdeempezar">Antes de empezar</h2>
<p>Normalmente en los despliegues que hacemos en AWS en <a href="http://crononauta.com">Crononauta</a>, siempre utilizamos un mínimo de un par de instancias EC2 para el sistema de almacenamiento en red con <strong>GlusterFS</strong>. Además, a cada una de estas dos instancias EC2, hacemos <em>attach</em> de un disco EBS donde almacenaremos los ficheros en el clúster de ficheros en red. Esto nos permite tener <strong>redundancia</strong> en los datos, <strong>alta disponibilidad</strong> y <strong>escalabilidad horizontal</strong> en el servicio. Con lo cual, tendremos un par de instancias que mantienen en clúster de almacenamiento actuando como GlusterFS Server y por otro lado, tendremos los clientes de GlusterFS que montarán este volumen compartido por la red.</p>
<p>Como detalle, en <strong>Crononauta</strong> siempre usamos Debian como distribución, en este caso contamos con una Debian 8 (Jessie), aunque es totalmente aplicable a cualquier distribución basada en Debian como Ubuntu y/o derivadas.</p>
<p>Una vez tenemos esto, podemos empezar a trabajar... ;-)</p>
<h2 id="particionandolosdiscos">Particionando los discos</h2>
<p>Utilizaremos <strong>XFS</strong> como sistema de ficheros para el volumen compartido en red. Por lo que necesitaremos instalar las utilidades para trabajar con XFS, si no las tenemos ya instaladas.</p>
<pre><code>apt-get install xfsprogs
</code></pre>
<p>El siguiente paso será crear una partición en el volumen, en mi caso es <code>/dev/xvdf</code>. Usaremos <code>fdisk</code> para ello:</p>
<pre><code>fdisk /dev/xvdf
</code></pre>
<p>y una vez en la shell interactiva de <code>fdisk</code>, teclearemos:</p>
<ol>
<li><code>n</code> para crear una nueva partición. No necesitamos especificar nada más, así que los siguientes datos que pide podemos usar los valores por defecto que ofrece <code>fdisk</code>, asi que pulsaremos <code>Intro</code> hasta finalizar. Una vez hecho esto, seguiremos dentro de la shell interactiva de <code>fdisk</code>, y habremos creado una partición primaria que ocupa todo el espacio del volumen.</li>
<li><code>w</code> indicando que queremos escribir esta definición de partición en el disco y hacerla efectiva.</li>
</ol>
<p>Ya tenemos la partición en el volumen, así que ahora la formatearemos y la añadiremos a nuestro <code>/etc/fstab</code> para montarla en cada arranque del sistema. Seguiremos los siguientes pasos:</p>
<pre><code>mkfs.xfs -i size=512 /dev/xvdf1
mkdir -p /export/brick1
echo "/dev/xvdf1 /export/brick1 xfs defaults 1 2"  &gt;&gt; /etc/fstab
mount -a &amp;&amp; mount
</code></pre>
<h2 id="instalandoglusterfs">Instalando GlusterFS</h2>
<p>Ya tenemos el volumen preparado para GlusterFS, ahora instalaremos el servicio.</p>
<pre><code>apt-get update
apt-get install glusterfs-server glusterfs-client glusterfs-common
</code></pre>
<p>Importante realizar este paso en aquellas instancias / servidores que vayan a actuar como un GlusterFS Server.</p>
<p>Lo siguiente que haremos será configurar nuestro fichero <code>/etc/hosts</code> para definir unos nombres DNS para nuestros GlusterFS Servers. También es posible hacerlo con un DNS interno. Si vuestros servidores, como en el caso de AWS EC2, contáis con IPs privadas, mejor usar esas. Si no, podéis usar las IPs pública.</p>
<p>Definiremos algo como lo siguiente en <code>/etc/hosts</code>:</p>
<pre><code>xxx.xxx.xxx.xxx    gfs01.example.com
xxx.xxx.xxx.xxx    gfs02.example.com
</code></pre>
<h2 id="unanilloparagobernarlosatodos">Un anillo para gobernarlos a todos</h2>
<p>Ya tenemos GlusterFS preparado para ser configurado. Ahora tendremos que configurar el <em>anillo de confianza</em> entre ambos servidores GlusterFS Server. Para ello serán necesarios los siguientes pasos:</p>
<ol>
<li>
<p>Desde <code>gfs01.example.com</code>:</p>
<pre><code> gluster peer probe gfs02.example.com
</code></pre>
</li>
<li>
<p>Desde <code>gfs02.example.com</code>:</p>
<pre><code> gluster peer probe gfs01.example.com
</code></pre>
</li>
</ol>
<p>Es <strong>muy importante</strong> que haya conectividad entre ambos servidores, en caso contrario, los comandos anteriores fallarán. Si estás en AWS, asegúrate de tener bien configurado el <strong>Security Group</strong> para ambas instancias de storage.</p>
<p>Si todo ha ido bien, tendremos el pool de confianza funcionando, así que lo siguiente será definir el volumen compartido. Usaremos la siguiente instrucción desde uno de los servidores GlusterFS:</p>
<pre><code>gluster volume create gv0 replica 2 gfs01.example.com:/export/brick1/&lt;volume-name&gt; gfs02.example.com:/export/brick1/&lt;volumen-name»
</code></pre>
<p>Por último, iniciaremos el volumen que justo acabamos de crear:</p>
<pre><code>gluster volume start gv0
</code></pre>
<p>Como detalle, podemos ver información sobre el volumen con la siguiente instrucción:</p>
<pre><code>gluster volume info
</code></pre>
<p>Llegados a este punto, el cluster de almacenamiento debe estar totalmente operativo. Si queremos hacer una prueba, es posible crear el punto de montaje hacia el volumen compartido y probar si se replican correctamente los ficheros. Crearemos el punto de montaje en <code>gfs01.example.com</code> de la siguiente forma:</p>
<pre><code>mount -t glusterfs localhost:/gv0 /mnt
</code></pre>
<p>Ahora crearemos ficheros para comprobar si el funcionamiento de GlusterFS es correcto. Con la siguiente instrucción crearemos diez ficheros vacíos en el punto de montaje previamente creado:</p>
<pre><code>touch /mnt/test-file{1..10}.txt
</code></pre>
<p>Si GlusterFS funciona correctamente, debemos poder ver estos mismos ficheros en <code>gfs02.example.com</code> en el directorio <code>/export/brick1/&lt;volume-name&gt;</code>.</p>
<h2 id="configurandolosclientes">Configurando los clientes</h2>
<p>Nos falta muy poco para terminar, ya sólo nos falta configurar los clientes de GlusterFS. Necesitaremos tener instalado el cliente de GlusterFS <code>glusterfs-client</code> si no lo tenemos instalado.</p>
<pre><code>apt-get install glusterfs-client
</code></pre>
<p>Hecho esto, podremos probar a montar el volumen compartido por la red, y si todo va bien debemos ver los ficheros de prueba creados previamente.</p>
<pre><code>mount -t glusterfs gfs01.example.com:/gv0 /mnt
</code></pre>
<p>Por último, necesitaremos un script <code>/etc/init.d/glusterfs-mount</code> que se encargue de montar el volumen compartido. En mi caso suelo utilizar el siguiente script:</p>
<pre><code>#! /bin/bash
### BEGIN INIT INFO
# Provides:          glusterfs-mount
# Required-Start:    $remote_fs $syslog
# Required-Stop:     $remote_fs $syslog
# Default-Start:     2 3 4 5 
# Default-Stop:      0 1 6 
# Short-Description: Start daemon at boot time
# Description:       Enable service provided by daemon.
### END INIT INFO
#

MOUNTPOINT="/var/www/shared"
GLUSTERFS_SERVER="gfs01.example.com"
GLUSTERFS_VOLUME="gv0"

# Some things that run always at boot
mount -t glusterfs $GLUSTERFS_SERVER:/$GLUSTERFS_VOLUME $MOUNTPOINT
#
# Uncomment this line if you need to start Apache after mount glusterFS volume
# service apache2 start
#
# Carry out specific functions when asked to by the system
case "$1" in
  start)
    echo "Mounting glusterfs volumes "
    mount -t glusterfs $GLUSTERFS_SERVER:/$GLUSTERFS_VOLUME $MOUNTPOINT
    ;;
  stop)
    echo "Unmount glusterfs volumes"
    umount $MOUNTPOINT
    ;;
  *)
    echo "Usage: /etc/init.d/glusterfs-mount {start|stop}"
    exit 1
    ;;
esac
exit 0
</code></pre>
<p>Ya solo nos queda dar permisos de ejecución a nuestro script y configurarlo para que se ejecute durante el inicio del sistema:</p>
<pre><code>chmod +x /etc/init.d/glusterfs-mount
update-rc.d glusterfs-mount defaults
</code></pre>
<h3 id="faq">FAQ</h3>
<ul>
<li><strong>Q:</strong> No puedo crear el anillo de confianza. Los comandos <code>gluster peer probe</code> terminan fallando con un timeout ¿Qué ocurre?</li>
</ul>
<ul>
<li><strong>A:</strong> Es muy probable que sea un problema de conectividad entre ambos GlusterFS Servers. Revisa si hay algún firewall entre ellos que pueda estar bloqueando conexiones TCP y UDP<br />
entre ellos. Puedes ver los puertos abiertos con <code>netstat -ntlp</code>.</li>
</ul>
<p>Si estás en AWS, asegúrate que el <strong>Security Group</strong> que usan ambas instancias tienen permitidos los accesos a puerto TCP y UDP entre ellos.</p>
<ul>
<li><strong>Q:</strong> No puedo montar el volumen compartido desde las instancias que actuan como clientes. El comando <code>mount</code> responde con <code>mount failed</code>. ¿Qué puede estar ocurriendo?</li>
</ul>
<ul>
<li><strong>A:</strong> Al igual que con los servidores GlusterFS, revisa que las instancias clientes tienen conectividad con los servidores. GlusterFS suele abrir un rango de puertos para cada volumen exportado (gv0, gv1, gv2, etc). Es recomendable permitir todo el tráfico TCP y UDP entre las instancias clientes y servidor. De otra forma es probable que alguna vez tengamos problemas al montar los volumenes.</li>
</ul>
<ul>
<li><strong>Q:</strong> Sigo sin poder crear el punto de montaje desde las instancias clientes. El comando <code>mount</code> indica que hubo un problema. La conectividad entre cliente y servidor de GlusterFS es correcta ¿Qué problema puede haber?</li>
</ul>
<ul>
<li><strong>A:</strong> Es muy común que las versiones de las distribuciones entre cliente y servidor difieran. Si esto es así, es muy probable que la versión de <code>glusterfs-client</code> difiera de la versión de <code>glusterfs-server</code>. En este caso, es muy probable que no podamos montar el volumen compartido con el driver <code>glusterfs</code>.</li>
</ul>
<p>GlusterFS permite montar los volumenes con el driver de NFS. En este tipo de situaciones es normal recurrir al driver de NFS para crear el punto de montaje. Para ello se necesita tener instalado <code>nfs-common</code> y crear el punto de montaje con la siguiente instrucción:</p>
<pre><code>mount -t nfs gfs01.example.com:/gv0 /var/www/shared
</code></pre>
<ul>
<li><strong>Q:</strong> ¿Por qué crear un script en <code>/etc/init.d</code> pudiendo configurar el montaje en el fichero <code>/etc/fstab</code>?</li>
</ul>
<ul>
<li><strong>A:</strong> Sí, es posible configurar el punto de montaje en <code>/etc/fstab</code>, pero a diferencia del resto de punto de montajes, en este caso se trata de un volumen compartido por la red. Es muy probable que cuando se monten los volumenes de <code>/etc/fstab</code>, aún no esté disponible la red en el sistema, con lo cual el montaje no solo fallará, sino que además es posible que ralentize el arranque del sistema hasta que el intento de montar el volumen por la red de un Timeout. Por eso es más fiable hacerlo con un script en <code>init.d</code>, una vez la red ya esté disponible.</li>
</ul>
<p>Creo que esto es todo. ¿Encontráis algún otro problema? ¡Dejadlo en los comentarios!<br />
Saludos.</p>


            </section>

        </article>
    </main>
    <footer class="site-footer clearfix">
        <section class="copyright"><a href="../../../index.html">Manuel Viera</a> &copy; 2020</section>
        <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
    </footer>
</body>
</html>
